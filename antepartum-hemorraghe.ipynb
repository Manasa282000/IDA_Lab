{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12167145,"sourceType":"datasetVersion","datasetId":7663171},{"sourceId":12170660,"sourceType":"datasetVersion","datasetId":7665217}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Explainability in Antepartum Hemorraghe ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objects as go\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import KNNImputer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T18:38:17.745979Z","iopub.execute_input":"2025-06-15T18:38:17.746325Z","iopub.status.idle":"2025-06-15T18:38:17.752025Z","shell.execute_reply.started":"2025-06-15T18:38:17.746298Z","shell.execute_reply":"2025-06-15T18:38:17.750885Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"# Specify the file path\ndf = pd.read_excel(r\"/kaggle/input/aph-dataset/4501_AMANHI_With_USG.xlsx\")\ndf.head(3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T18:38:22.151574Z","iopub.execute_input":"2025-06-15T18:38:22.151936Z","iopub.status.idle":"2025-06-15T18:38:27.260769Z","shell.execute_reply.started":"2025-06-15T18:38:22.151911Z","shell.execute_reply":"2025-06-15T18:38:27.259742Z"}},"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"      WHOWID  ORIG_ID PARTICIPANT_ID  PW_AGE  PW_EDUCATION  PREV_SB  PREV_MIS  \\\n0  20-016580    16580  AMANHIT-20916      36          10.0        1         2   \n1  20-016683    16683  AMANHIT-22194      32          10.0        0         0   \n2  20-016685    16685  AMANHIT-22712      18           6.0        0         1   \n\n   PREV_PTB  PREV_MULTIP  PREV_CS  ...  DBP4  UDIP_PROT4   DEL_DATE  GAGEBRTH  \\\n0         0            1        0  ...  69.0         0.0 2014-10-31     271.0   \n1         0            0        0  ...  73.0         0.0 2015-01-06     274.0   \n2         0            0        0  ...  70.0         0.0 2015-01-31     290.0   \n\n                     TYPEDELIV  age_death_b1  age_death_b2  age_death_b3  APH  \\\n0  Normally through the vagina           NaN           NaN           NaN  0.0   \n1  Normally through the vagina           NaN           NaN           NaN  0.0   \n2  Normally through the vagina           NaN           NaN           NaN  0.0   \n\n  MAT_WEIGHT  \n0       45.8  \n1        NaN  \n2       68.0  \n\n[3 rows x 51 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>WHOWID</th>\n      <th>ORIG_ID</th>\n      <th>PARTICIPANT_ID</th>\n      <th>PW_AGE</th>\n      <th>PW_EDUCATION</th>\n      <th>PREV_SB</th>\n      <th>PREV_MIS</th>\n      <th>PREV_PTB</th>\n      <th>PREV_MULTIP</th>\n      <th>PREV_CS</th>\n      <th>...</th>\n      <th>DBP4</th>\n      <th>UDIP_PROT4</th>\n      <th>DEL_DATE</th>\n      <th>GAGEBRTH</th>\n      <th>TYPEDELIV</th>\n      <th>age_death_b1</th>\n      <th>age_death_b2</th>\n      <th>age_death_b3</th>\n      <th>APH</th>\n      <th>MAT_WEIGHT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20-016580</td>\n      <td>16580</td>\n      <td>AMANHIT-20916</td>\n      <td>36</td>\n      <td>10.0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>69.0</td>\n      <td>0.0</td>\n      <td>2014-10-31</td>\n      <td>271.0</td>\n      <td>Normally through the vagina</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>45.8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20-016683</td>\n      <td>16683</td>\n      <td>AMANHIT-22194</td>\n      <td>32</td>\n      <td>10.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>73.0</td>\n      <td>0.0</td>\n      <td>2015-01-06</td>\n      <td>274.0</td>\n      <td>Normally through the vagina</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20-016685</td>\n      <td>16685</td>\n      <td>AMANHIT-22712</td>\n      <td>18</td>\n      <td>6.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>70.0</td>\n      <td>0.0</td>\n      <td>2015-01-31</td>\n      <td>290.0</td>\n      <td>Normally through the vagina</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>68.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 51 columns</p>\n</div>"},"metadata":{}}],"execution_count":56},{"cell_type":"code","source":"df = df.replace([-88, -77], np.nan)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T18:38:31.377068Z","iopub.execute_input":"2025-06-15T18:38:31.377705Z","iopub.status.idle":"2025-06-15T18:38:31.402170Z","shell.execute_reply.started":"2025-06-15T18:38:31.377662Z","shell.execute_reply":"2025-06-15T18:38:31.400877Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T18:38:33.248481Z","iopub.execute_input":"2025-06-15T18:38:33.248852Z","iopub.status.idle":"2025-06-15T18:38:33.269151Z","shell.execute_reply.started":"2025-06-15T18:38:33.248823Z","shell.execute_reply":"2025-06-15T18:38:33.267361Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4501 entries, 0 to 4500\nData columns (total 51 columns):\n #   Column          Non-Null Count  Dtype         \n---  ------          --------------  -----         \n 0   WHOWID          4501 non-null   object        \n 1   ORIG_ID         4501 non-null   int64         \n 2   PARTICIPANT_ID  4501 non-null   object        \n 3   PW_AGE          4501 non-null   int64         \n 4   PW_EDUCATION    4485 non-null   float64       \n 5   PREV_SB         3700 non-null   float64       \n 6   PREV_MIS        3700 non-null   float64       \n 7   PREV_PTB        3505 non-null   float64       \n 8   PREV_MULTIP     3700 non-null   float64       \n 9   PREV_CS         3700 non-null   float64       \n 10  WEALTH_INDEX    4501 non-null   object        \n 11  SINGLE_TWIN     4386 non-null   float64       \n 12  GRAVIDITY       4485 non-null   float64       \n 13  PARITY          3700 non-null   float64       \n 14  LABOUR_HTN      3960 non-null   float64       \n 15  LABOUR_24       3979 non-null   float64       \n 16  BIRTH_OUTCOME   4386 non-null   float64       \n 17  BABY_SEX        4169 non-null   float64       \n 18  BIRTH_WEIGHT    3943 non-null   float64       \n 19  BABY_ID1        4501 non-null   object        \n 20  BIRTH_OUTCOME1  4386 non-null   float64       \n 21  BABY_SEX1       4169 non-null   float64       \n 22  BIRTH_WEIGHT1   3943 non-null   float64       \n 23  BABY_ID2        90 non-null     object        \n 24  BIRTH_OUTCOME2  90 non-null     float64       \n 25  BABY_SEX2       83 non-null     float64       \n 26  BIRTH_WEIGHT2   78 non-null     float64       \n 27  BABY_ID3        2 non-null      object        \n 28  BIRTH_OUTCOME3  2 non-null      float64       \n 29  BABY_SEX3       2 non-null      float64       \n 30  BIRTH_WEIGHT3   2 non-null      float64       \n 31  SBP1            4302 non-null   float64       \n 32  DBP1            4302 non-null   float64       \n 33  UDIP_PROT1      4272 non-null   float64       \n 34  SBP2            4209 non-null   float64       \n 35  DBP2            4209 non-null   float64       \n 36  UDIP_PROT2      4152 non-null   float64       \n 37  SBP3            4107 non-null   float64       \n 38  DBP3            4107 non-null   float64       \n 39  UDIP_PROT3      4018 non-null   float64       \n 40  SBP4            3843 non-null   float64       \n 41  DBP4            3843 non-null   float64       \n 42  UDIP_PROT4      3724 non-null   float64       \n 43  DEL_DATE        4366 non-null   datetime64[ns]\n 44  GAGEBRTH        4366 non-null   float64       \n 45  TYPEDELIV       4277 non-null   object        \n 46  age_death_b1    87 non-null     float64       \n 47  age_death_b2    12 non-null     float64       \n 48  age_death_b3    0 non-null      float64       \n 49  APH             4414 non-null   float64       \n 50  MAT_WEIGHT      4170 non-null   float64       \ndtypes: datetime64[ns](1), float64(41), int64(2), object(7)\nmemory usage: 1.8+ MB\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"df.drop(['ORIG_ID','PARTICIPANT_ID','BIRTH_OUTCOME','BABY_SEX','BIRTH_WEIGHT','LABOUR_HTN','GAGEBRTH','BABY_ID1','BABY_ID2','BABY_ID3','WHOWID','BIRTH_OUTCOME2','BIRTH_WEIGHT2','BIRTH_OUTCOME3','BABY_SEX3','BIRTH_WEIGHT3','WEALTH_INDEX','DEL_DATE','age_death_b1','age_death_b2','age_death_b3','BABY_SEX2','TYPEDELIV','BIRTH_OUTCOME1','BABY_SEX1','BIRTH_WEIGHT1'], axis=1, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T18:38:36.470087Z","iopub.execute_input":"2025-06-15T18:38:36.470427Z","iopub.status.idle":"2025-06-15T18:38:36.478127Z","shell.execute_reply.started":"2025-06-15T18:38:36.470399Z","shell.execute_reply":"2025-06-15T18:38:36.476795Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"df_nonAPH = df[df[\"APH\"] == 0]\ndf_APH = df[df[\"APH\"] == 1]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T18:38:38.144892Z","iopub.execute_input":"2025-06-15T18:38:38.145219Z","iopub.status.idle":"2025-06-15T18:38:38.154387Z","shell.execute_reply.started":"2025-06-15T18:38:38.145194Z","shell.execute_reply":"2025-06-15T18:38:38.153289Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"import pandas as pd\n\n# Columns to be imputed\nnumerical_columns = ['SBP1', 'DBP1', 'UDIP_PROT1', 'SBP2', 'DBP2', 'UDIP_PROT2', \n                     'SBP3', 'DBP3', 'UDIP_PROT3', 'SBP4', 'DBP4', 'UDIP_PROT4', \n                     'MAT_WEIGHT', 'GRAVIDITY', 'PARITY']\n\ncategorical_columns = ['PW_EDUCATION', 'LABOUR_24', 'SINGLE_TWIN', 'PREV_SB', \n                       'PREV_MIS', 'PREV_PTB', 'PREV_MULTIP', 'PREV_CS']\n\n# Fill missing values in numerical columns using median\nfor col in numerical_columns:\n    median_value_nonAPH = df_nonAPH[col].median()\n    df_nonAPH[col].fillna(median_value_nonAPH, inplace=True)\n    \n    median_value_APH = df_APH[col].median()\n    df_APH[col].fillna(median_value_APH, inplace=True)\n\n# Fill missing values in categorical columns using mode\nfor col in categorical_columns:\n    mode_value_nonAPH = df_nonAPH[col].mode()[0]  # Get the most frequent value\n    df_nonAPH[col].fillna(mode_value_nonAPH, inplace=True)\n    \n    mode_value_APH = df_APH[col].mode()[0]  # Get the most frequent value\n    df_APH[col].fillna(mode_value_APH, inplace=True)\n\n# Check for remaining missing values\nprint(\"Missing values in df_nonAPH after imputation:\")\nprint(df_nonAPH[numerical_columns + categorical_columns].isnull().sum())\n\nprint(\"\\nMissing values in df_APH after imputation:\")\nprint(df_APH[numerical_columns + categorical_columns].isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T18:38:39.973130Z","iopub.execute_input":"2025-06-15T18:38:39.973468Z","iopub.status.idle":"2025-06-15T18:38:40.010746Z","shell.execute_reply.started":"2025-06-15T18:38:39.973441Z","shell.execute_reply":"2025-06-15T18:38:40.009668Z"}},"outputs":[{"name":"stdout","text":"Missing values in df_nonAPH after imputation:\nSBP1            0\nDBP1            0\nUDIP_PROT1      0\nSBP2            0\nDBP2            0\nUDIP_PROT2      0\nSBP3            0\nDBP3            0\nUDIP_PROT3      0\nSBP4            0\nDBP4            0\nUDIP_PROT4      0\nMAT_WEIGHT      0\nGRAVIDITY       0\nPARITY          0\nPW_EDUCATION    0\nLABOUR_24       0\nSINGLE_TWIN     0\nPREV_SB         0\nPREV_MIS        0\nPREV_PTB        0\nPREV_MULTIP     0\nPREV_CS         0\ndtype: int64\n\nMissing values in df_APH after imputation:\nSBP1            0\nDBP1            0\nUDIP_PROT1      0\nSBP2            0\nDBP2            0\nUDIP_PROT2      0\nSBP3            0\nDBP3            0\nUDIP_PROT3      0\nSBP4            0\nDBP4            0\nUDIP_PROT4      0\nMAT_WEIGHT      0\nGRAVIDITY       0\nPARITY          0\nPW_EDUCATION    0\nLABOUR_24       0\nSINGLE_TWIN     0\nPREV_SB         0\nPREV_MIS        0\nPREV_PTB        0\nPREV_MULTIP     0\nPREV_CS         0\ndtype: int64\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_169/187461951.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df_nonAPH[col].fillna(median_value_nonAPH, inplace=True)\n/tmp/ipykernel_169/187461951.py:14: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_nonAPH[col].fillna(median_value_nonAPH, inplace=True)\n/tmp/ipykernel_169/187461951.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df_APH[col].fillna(median_value_APH, inplace=True)\n/tmp/ipykernel_169/187461951.py:17: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_APH[col].fillna(median_value_APH, inplace=True)\n/tmp/ipykernel_169/187461951.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df_nonAPH[col].fillna(mode_value_nonAPH, inplace=True)\n/tmp/ipykernel_169/187461951.py:22: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_nonAPH[col].fillna(mode_value_nonAPH, inplace=True)\n/tmp/ipykernel_169/187461951.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df_APH[col].fillna(mode_value_APH, inplace=True)\n/tmp/ipykernel_169/187461951.py:25: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_APH[col].fillna(mode_value_APH, inplace=True)\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming train_set_nonAPH, train_set_APH, test_set_nonAPH, test_set_APH are pandas DataFrames\n\n# Merge the train datasets\ndf = pd.concat([df_nonAPH, df_APH], axis=0)\n\n# Reset the index (optional, to clean up any duplicate indices after concatenation)\ndf.reset_index(drop=True, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T18:38:43.785595Z","iopub.execute_input":"2025-06-15T18:38:43.786098Z","iopub.status.idle":"2025-06-15T18:38:43.793355Z","shell.execute_reply.started":"2025-06-15T18:38:43.786065Z","shell.execute_reply":"2025-06-15T18:38:43.792217Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"df.info()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T18:38:45.600116Z","iopub.execute_input":"2025-06-15T18:38:45.600438Z","iopub.status.idle":"2025-06-15T18:38:45.624228Z","shell.execute_reply.started":"2025-06-15T18:38:45.600410Z","shell.execute_reply":"2025-06-15T18:38:45.611086Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4414 entries, 0 to 4413\nData columns (total 25 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   PW_AGE        4414 non-null   int64  \n 1   PW_EDUCATION  4414 non-null   float64\n 2   PREV_SB       4414 non-null   float64\n 3   PREV_MIS      4414 non-null   float64\n 4   PREV_PTB      4414 non-null   float64\n 5   PREV_MULTIP   4414 non-null   float64\n 6   PREV_CS       4414 non-null   float64\n 7   SINGLE_TWIN   4414 non-null   float64\n 8   GRAVIDITY     4414 non-null   float64\n 9   PARITY        4414 non-null   float64\n 10  LABOUR_24     4414 non-null   float64\n 11  SBP1          4414 non-null   float64\n 12  DBP1          4414 non-null   float64\n 13  UDIP_PROT1    4414 non-null   float64\n 14  SBP2          4414 non-null   float64\n 15  DBP2          4414 non-null   float64\n 16  UDIP_PROT2    4414 non-null   float64\n 17  SBP3          4414 non-null   float64\n 18  DBP3          4414 non-null   float64\n 19  UDIP_PROT3    4414 non-null   float64\n 20  SBP4          4414 non-null   float64\n 21  DBP4          4414 non-null   float64\n 22  UDIP_PROT4    4414 non-null   float64\n 23  APH           4414 non-null   float64\n 24  MAT_WEIGHT    4414 non-null   float64\ndtypes: float64(24), int64(1)\nmemory usage: 862.2 KB\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"df['APH'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T18:38:48.280347Z","iopub.execute_input":"2025-06-15T18:38:48.281229Z","iopub.status.idle":"2025-06-15T18:38:48.288487Z","shell.execute_reply.started":"2025-06-15T18:38:48.281195Z","shell.execute_reply":"2025-06-15T18:38:48.287546Z"}},"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"APH\n0.0    4243\n1.0     171\nName: count, dtype: int64"},"metadata":{}}],"execution_count":64},{"cell_type":"code","source":"# Apply one-hot encoding with pd.get_dummies\ndf = pd.get_dummies(df, columns=['LABOUR_24'], drop_first=True)\n\n\n# Verify and explicitly convert the encoded column to integer\ndf['LABOUR_24_1.0'] = df['LABOUR_24_1.0'].astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T18:38:49.840409Z","iopub.execute_input":"2025-06-15T18:38:49.841398Z","iopub.status.idle":"2025-06-15T18:38:49.850991Z","shell.execute_reply.started":"2025-06-15T18:38:49.841355Z","shell.execute_reply":"2025-06-15T18:38:49.849854Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T18:38:52.385758Z","iopub.execute_input":"2025-06-15T18:38:52.386217Z","iopub.status.idle":"2025-06-15T18:38:52.399495Z","shell.execute_reply.started":"2025-06-15T18:38:52.386185Z","shell.execute_reply":"2025-06-15T18:38:52.398338Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4414 entries, 0 to 4413\nData columns (total 25 columns):\n #   Column         Non-Null Count  Dtype  \n---  ------         --------------  -----  \n 0   PW_AGE         4414 non-null   int64  \n 1   PW_EDUCATION   4414 non-null   float64\n 2   PREV_SB        4414 non-null   float64\n 3   PREV_MIS       4414 non-null   float64\n 4   PREV_PTB       4414 non-null   float64\n 5   PREV_MULTIP    4414 non-null   float64\n 6   PREV_CS        4414 non-null   float64\n 7   SINGLE_TWIN    4414 non-null   float64\n 8   GRAVIDITY      4414 non-null   float64\n 9   PARITY         4414 non-null   float64\n 10  SBP1           4414 non-null   float64\n 11  DBP1           4414 non-null   float64\n 12  UDIP_PROT1     4414 non-null   float64\n 13  SBP2           4414 non-null   float64\n 14  DBP2           4414 non-null   float64\n 15  UDIP_PROT2     4414 non-null   float64\n 16  SBP3           4414 non-null   float64\n 17  DBP3           4414 non-null   float64\n 18  UDIP_PROT3     4414 non-null   float64\n 19  SBP4           4414 non-null   float64\n 20  DBP4           4414 non-null   float64\n 21  UDIP_PROT4     4414 non-null   float64\n 22  APH            4414 non-null   float64\n 23  MAT_WEIGHT     4414 non-null   float64\n 24  LABOUR_24_1.0  4414 non-null   int64  \ndtypes: float64(23), int64(2)\nmemory usage: 862.2 KB\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"X = df.drop(columns=['APH','PW_EDUCATION'])\ny = df['APH']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T18:38:54.689844Z","iopub.execute_input":"2025-06-15T18:38:54.690171Z","iopub.status.idle":"2025-06-15T18:38:54.696696Z","shell.execute_reply.started":"2025-06-15T18:38:54.690150Z","shell.execute_reply":"2025-06-15T18:38:54.695670Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"X.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T18:38:57.996714Z","iopub.execute_input":"2025-06-15T18:38:57.997076Z","iopub.status.idle":"2025-06-15T18:38:58.008735Z","shell.execute_reply.started":"2025-06-15T18:38:57.997017Z","shell.execute_reply":"2025-06-15T18:38:58.007666Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4414 entries, 0 to 4413\nData columns (total 23 columns):\n #   Column         Non-Null Count  Dtype  \n---  ------         --------------  -----  \n 0   PW_AGE         4414 non-null   int64  \n 1   PREV_SB        4414 non-null   float64\n 2   PREV_MIS       4414 non-null   float64\n 3   PREV_PTB       4414 non-null   float64\n 4   PREV_MULTIP    4414 non-null   float64\n 5   PREV_CS        4414 non-null   float64\n 6   SINGLE_TWIN    4414 non-null   float64\n 7   GRAVIDITY      4414 non-null   float64\n 8   PARITY         4414 non-null   float64\n 9   SBP1           4414 non-null   float64\n 10  DBP1           4414 non-null   float64\n 11  UDIP_PROT1     4414 non-null   float64\n 12  SBP2           4414 non-null   float64\n 13  DBP2           4414 non-null   float64\n 14  UDIP_PROT2     4414 non-null   float64\n 15  SBP3           4414 non-null   float64\n 16  DBP3           4414 non-null   float64\n 17  UDIP_PROT3     4414 non-null   float64\n 18  SBP4           4414 non-null   float64\n 19  DBP4           4414 non-null   float64\n 20  UDIP_PROT4     4414 non-null   float64\n 21  MAT_WEIGHT     4414 non-null   float64\n 22  LABOUR_24_1.0  4414 non-null   int64  \ndtypes: float64(21), int64(2)\nmemory usage: 793.3 KB\n","output_type":"stream"}],"execution_count":68},{"cell_type":"code","source":"!pip install -U scikit-learn imbalanced-learn\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install --force-reinstall --upgrade scikit-learn==1.3.2 imbalanced-learn==0.11.0\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install gosdt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T18:39:04.678494Z","iopub.execute_input":"2025-06-15T18:39:04.678844Z","iopub.status.idle":"2025-06-15T18:39:04.689677Z","shell.execute_reply.started":"2025-06-15T18:39:04.678818Z","shell.execute_reply":"2025-06-15T18:39:04.688625Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"nb = NumericBinarizer()\nnb.set_output(transform=\"pandas\")\nX_train_num = nb.fit_transform(X_train.copy(), X_train.copy())\nX_test_num = nb.transform(X_test.copy())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test_num","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom imblearn.over_sampling import SMOTE\nfrom gosdt import ThresholdGuessBinarizer, GOSDTClassifier\n\n# Step 1: Define your cleaned data\n\n\n# Step 2: Stratified Split\n\n# Step 3: Apply SMOTE to training data only\nsmote = SMOTE(random_state=42,sampling_strategy=0.5)\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n\nprint(\"Original training shape:\", X_train.shape, y_train.shape)\nprint(\"After SMOTE:\", X_train_resampled.shape, y_train_resampled.shape)\n\n# Step 4: Threshold Guessing\nX_train_resampled_df = pd.DataFrame(X_train_resampled)\nX_test_df = pd.DataFrame(X_test)\n\nenc = ThresholdGuessBinarizer(n_estimators=200, max_depth=1, random_state=42)\nenc.set_output(transform=\"pandas\")\nX_train_guessed = enc.fit_transform(X_train_resampled_df, y_train_resampled)\nX_test_guessed = enc.transform(X_test_df)\n\nprint(f\"After threshold guessing: X_train_guessed shape: {X_train_guessed.shape}, X_test_guessed shape: {X_test_guessed.shape}\")\n\n# Step 5: Warm start labels using Gradient Boosting\ngbdt = GradientBoostingClassifier(n_estimators=80, max_depth=5, random_state=42)\ngbdt.fit(X_train_guessed, y_train_resampled)\nwarm_labels = gbdt.predict(X_train_guessed)\n\n# Step 6: Train GOSDT\nclf = GOSDTClassifier(\n    regularization=0.001,\n    similar_support=False,\n    time_limit=1800,\n    depth_budget=4,\n    verbose=True\n)\nclf.fit(X_train_guessed, y_train_resampled, y_ref=warm_labels)\n\n# Step 7: Evaluate\nprint(f\"\\nModel training time: {clf.result_.time}\")\nprint(f\"Training accuracy: {clf.score(X_train_guessed, y_train_resampled)}\")\nprint(f\"Test accuracy: {clf.score(X_test_guessed, y_test)}\")\n\n# Step 8: Optional - Display Class Distribution\nprint(\"\\nClass distribution in y_train after SMOTE:\")\nprint(pd.Series(y_train_resampled).value_counts(normalize=True))\n\nprint(\"\\nClass distribution in y_test:\")\nprint(y_test.value_counts(normalize=True))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T18:40:32.302598Z","iopub.execute_input":"2025-06-15T18:40:32.302952Z","iopub.status.idle":"2025-06-15T18:40:58.640639Z","shell.execute_reply.started":"2025-06-15T18:40:32.302925Z","shell.execute_reply":"2025-06-15T18:40:58.639618Z"}},"outputs":[{"name":"stdout","text":"Original training shape: (3531, 23) (3531,)\nAfter SMOTE: (5091, 23) (5091,)\nAfter threshold guessing: X_train_guessed shape: (5091, 32), X_test_guessed shape: (883, 32)\nUsing Configuration: {\n    \"cancellation\": true,\n    \"depth_budget\": 5,\n    \"diagnostics\": false,\n    \"feature_transform\": true,\n    \"look_ahead\": true,\n    \"model_limit\": 1,\n    \"non_binary\": false,\n    \"profile\": \"\",\n    \"reference_LB\": false,\n    \"regularization\": 0.0010000000474974513,\n    \"rule_list\": false,\n    \"similar_support\": false,\n    \"time_limit\": 1800,\n    \"trace\": \"\",\n    \"tree\": \"\",\n    \"upperbound\": 0.0,\n    \"verbose\": true,\n    \"worker_limit\": 1\n}\n\n[WARNING] The off-by-one in the depth_budget option here is a consequence of the C++ code treating unbounded depth trees as trees of depth 0 and single node leaf trees as trees of depth 1.\n\nInitializing Optimization Framework.\n\nModel training time: 13.464\nStarting Optimization.\nTime: 0, Objective: [0.0631061, 0.325316], Boundary: 0.26221, Graph Size: 1, Queue Size: 64\nTime: 1.786, Objective: [0.0631061, 0.325316], Boundary: 0.26221, Graph Size: 7940, Queue Size: 58305\nTime: 3.309, Objective: [0.0631061, 0.325316], Boundary: 0.26221, Graph Size: 14097, Queue Size: 60449\nTime: 4.785, Objective: [0.0631061, 0.325316], Boundary: 0.26221, Graph Size: 19021, Queue Size: 58108\nTime: 6.242, Objective: [0.0631061, 0.325316], Boundary: 0.26221, Graph Size: 23216, Queue Size: 52713\nTime: 7.632, Objective: [0.0631061, 0.325316], Boundary: 0.26221, Graph Size: 26659, Queue Size: 43792\nTime: 9.032, Objective: [0.0631061, 0.325316], Boundary: 0.26221, Graph Size: 29558, Queue Size: 34202\nTime: 10.367, Objective: [0.0631061, 0.325316], Boundary: 0.26221, Graph Size: 31909, Queue Size: 24812\nTime: 11.641, Objective: [0.0631061, 0.325316], Boundary: 0.26221, Graph Size: 33473, Queue Size: 15597\nTime: 11.961, Objective: [0.0631239, 0.318655], Boundary: 0.255531, Graph Size: 33782, Queue Size: 13181\nTime: 12.789, Objective: [0.0631239, 0.318655], Boundary: 0.255531, Graph Size: 34491, Queue Size: 6550\nTime: 13.082, Objective: [0.0631239, 0.198729], Boundary: 0.135605, Graph Size: 34710, Queue Size: 4010\nTime: 13.166, Objective: [0.0631239, 0.182015], Boundary: 0.118891, Graph Size: 34756, Queue Size: 3331\nTime: 13.367, Objective: [0.0631239, 0.172408], Boundary: 0.109284, Graph Size: 34860, Queue Size: 1353\nTime: 13.369, Objective: [0.0631239, 0.172211], Boundary: 0.109087, Graph Size: 34860, Queue Size: 1314\nTime: 13.397, Objective: [0.0631239, 0.134908], Boundary: 0.0717845, Graph Size: 34882, Queue Size: 932\nTime: 13.452, Objective: [0.0631239, 0.134908], Boundary: 0.0717845, Graph Size: 34904, Queue Size: 184\nTime: 13.461, Objective: [0.125927, 0.134908], Boundary: 0.00898193, Graph Size: 34904, Queue Size: 59\nTime: 13.464, Objective: [0.130284, 0.134908], Boundary: 0.00462483, Graph Size: 34904, Queue Size: 14\nTime: 13.464, Objective: [0.134908, 0.134908], Boundary: 0, Graph Size: 34904, Queue Size: 13\nOptimization Complete.\nTraining Duration: 13.464\nNumber of Optimizer Iterations: 98729\nSize of Problem Graph: 34904\nObjective Boundary: [0.134908, 0.134908]\nModels Generated: 1\nLoss: 0.125908\nComplexity: 0.009\nTraining accuracy: 0.8740915340797486\nTest accuracy: 0.9716874292185731\n\nClass distribution in y_train after SMOTE:\nAPH\n0.0    0.666667\n1.0    0.333333\nName: proportion, dtype: float64\n\nClass distribution in y_test:\nAPH\n0.0    0.961495\n1.0    0.038505\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"import sklearn\nimport imblearn\n\nprint(\"scikit-learn version:\", sklearn.__version__)\nprint(\"imbalanced-learn version:\", imblearn.__version__)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip uninstall -y scikit-learn imbalanced-learn\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install scikit-learn==1.3.2 imbalanced-learn==0.11.0\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import sklearn\nimport imblearn\n\nprint(\"scikit-learn version:\", sklearn.__version__)\nprint(\"imbalanced-learn version:\", imblearn.__version__)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip uninstall -y scikit-learn imbalanced-learn numpy scipy joblib threadpoolctl\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip cache purge\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install scikit-learn==1.3.2 imbalanced-learn==0.11.0 numpy==1.24.4 scipy==1.11.4\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# Predict test labels\ny_pred = clf.predict(X_test_guessed)\n\n# Generate classification report\nprint(\"\\nClassification Report on Test Set:\")\nprint(classification_report(y_test, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T18:41:35.937745Z","iopub.execute_input":"2025-06-15T18:41:35.938782Z","iopub.status.idle":"2025-06-15T18:41:35.959440Z","shell.execute_reply.started":"2025-06-15T18:41:35.938746Z","shell.execute_reply":"2025-06-15T18:41:35.958462Z"}},"outputs":[{"name":"stdout","text":"\nClassification Report on Test Set:\n              precision    recall  f1-score   support\n\n         0.0       0.97      1.00      0.99       849\n         1.0       1.00      0.26      0.42        34\n\n    accuracy                           0.97       883\n   macro avg       0.99      0.63      0.70       883\nweighted avg       0.97      0.97      0.96       883\n\n","output_type":"stream"}],"execution_count":73},{"cell_type":"code","source":"import gosdt\ndir(gosdt)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from gosdt import GOSDTClassifier\nimport inspect\n\nmethods = inspect.getmembers(GOSDTClassifier, predicate=inspect.isfunction)\nfor name, _ in methods:\n    print(name)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install gosdt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport time\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom imblearn.over_sampling import SMOTE\nfrom gosdt import GOSDTClassifier, ThresholdGuessBinarizer, NumericBinarizer\n\n# Load Antepartum Hemorrhage data\n#df = pd.read_csv(\"/content/aph.csv\")  # update path if needed\n#X, y = df.iloc[:, :-1], df.iloc[:, -1]\n\n# Set random seed and Stratified KFold\nSEED = 42\nskf = StratifiedKFold(n_splits=2, shuffle=True, random_state=SEED)\n\nmetrics = {\n    \"GOSDT_Guessed\": {\"train_acc\": [], \"test_acc\": []},\n    \"GOSDT_Numerical\": {\"train_acc\": [], \"test_acc\": []},\n    \"GBDT_Baseline\": {\"train_acc\": [], \"test_acc\": []},\n}\n\nfor fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n    print(f\"\\n=== Fold {fold + 1} ===\")\n\n    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n\n    # SMOTE on training data only\n    smote = SMOTE(random_state=SEED, sampling_strategy=0.8)\n    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n\n    # -------- GOSDT with ThresholdGuessBinarizer --------\n    print(\"-> GOSDT (ThresholdGuessBinarizer + y_ref)\")\n    tgb = ThresholdGuessBinarizer(n_estimators=200, max_depth=1, random_state=SEED)\n    tgb.set_output(transform=\"pandas\")\n    X_train_guess = tgb.fit_transform(X_train_res.copy(), y_train_res.copy())\n    X_test_guess = tgb.transform(X_test.copy())\n\n    gbdt_ref = GradientBoostingClassifier(n_estimators=80, max_depth=5, random_state=SEED)\n    gbdt_ref.fit(X_train_guess, y_train_res)\n    warm_labels = gbdt_ref.predict(X_train_guess)\n\n    clf_guess = GOSDTClassifier(regularization=0.001, depth_budget=3, time_limit=1800)\n    clf_guess.fit(X_train_guess, y_train_res, y_ref=warm_labels)\n\n    y_pred_train_g = clf_guess.predict(X_train_guess)\n    y_pred_test_g = clf_guess.predict(X_test_guess)\n\n    metrics[\"GOSDT_Guessed\"][\"train_acc\"].append(accuracy_score(y_train_res, y_pred_train_g))\n    metrics[\"GOSDT_Guessed\"][\"test_acc\"].append(accuracy_score(y_test, y_pred_test_g))\n\n    # -------- GOSDT with NumericBinarizer --------\n    print(\"-> GOSDT (NumericBinarizer)\")\n    nb = NumericBinarizer()\n    nb.set_output(transform=\"pandas\")\n    X_train_num = nb.fit_transform(X_train_res.copy(), y_train_res.copy())\n    X_test_num = nb.transform(X_test.copy())\n\n    clf_num = GOSDTClassifier(regularization=0.001, depth_budget=1, time_limit=1800)\n    clf_num.fit(X_train_num, y_train_res)\n\n    y_pred_train_n = clf_num.predict(X_train_num)\n    y_pred_test_n = clf_num.predict(X_test_num)\n\n    metrics[\"GOSDT_Numerical\"][\"train_acc\"].append(accuracy_score(y_train_res, y_pred_train_n))\n    metrics[\"GOSDT_Numerical\"][\"test_acc\"].append(accuracy_score(y_test, y_pred_test_n))\n\n    # -------- GBDT Baseline --------\n    print(\"-> GBDT Baseline\")\n    gbdt = GradientBoostingClassifier(n_estimators=60, max_depth=1, random_state=SEED)\n    gbdt.fit(X_train_res, y_train_res)\n\n    y_pred_train_b = gbdt.predict(X_train_res)\n    y_pred_test_b = gbdt.predict(X_test)\n\n    metrics[\"GBDT_Baseline\"][\"train_acc\"].append(accuracy_score(y_train_res, y_pred_train_b))\n    metrics[\"GBDT_Baseline\"][\"test_acc\"].append(accuracy_score(y_test, y_pred_test_b))\n\n# ------------------ Results ------------------\nprint(\"\\n=== Median Results Over 5 Folds ===\")\nfor model in metrics:\n    print(f\"\\n{model}:\")\n    print(f\"  Median Train Accuracy: {np.median(metrics[model]['train_acc']):.4f}\")\n    print(f\"  Median Test Accuracy:  {np.median(metrics[model]['test_acc']):.4f}\")\n\n# Optional: Plot\nlabels = list(metrics.keys())\nmedian_test_accuracies = [np.median(metrics[m][\"test_acc\"]) for m in labels]\n\nplt.figure(figsize=(8, 5))\nbars = plt.bar(labels, median_test_accuracies, color=[\"cornflowerblue\", \"lightcoral\", \"lightgreen\"])\nplt.ylabel(\"Median Test Accuracy\")\nplt.title(\"APH Dataset: GOSDT vs GBDT (SMOTE + Stratified KFold)\")\nfor bar in bars:\n    yval = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2.0, yval, f'{yval:.3f}', va='bottom', ha='center')\nplt.xticks(rotation=15)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport time\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom imblearn.over_sampling import SMOTE\nfrom gosdt import GOSDTClassifier, ThresholdGuessBinarizer, NumericBinarizer\n\n# Load Antepartum Hemorrhage data\n# df = pd.read_csv(\"/content/aph.csv\")  # Uncomment and update the path if needed\n# X, y = df.iloc[:, :-1], df.iloc[:, -1]\n\n# Set random seed and Stratified KFold\nSEED = 42\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n\nmetrics = {\n    \"GOSDT_Guessed\": {\"train_acc\": [], \"test_acc\": []},\n    \"GOSDT_Numerical\": {\"train_acc\": [], \"test_acc\": []},\n    \"GBDT_Baseline\": {\"train_acc\": [], \"test_acc\": []},\n}\n\ntimes = {\n    \"GOSDT_Guessed\": {\"train_time\": [], \"test_time\": []},\n    \"GOSDT_Numerical\": {\"train_time\": [], \"test_time\": []},\n    \"GBDT_Baseline\": {\"train_time\": [], \"test_time\": []},\n}\n\nfor fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n    print(f\"\\n=== Fold {fold + 1} ===\")\n\n    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n\n    # SMOTE on training data only\n    smote = SMOTE(random_state=SEED, sampling_strategy=1)\n    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n\n    # -------- GOSDT with ThresholdGuessBinarizer --------\n    print(\"-> GOSDT (ThresholdGuessBinarizer + y_ref)\")\n    tgb = ThresholdGuessBinarizer(n_estimators=200, max_depth=1, random_state=SEED)\n    tgb.set_output(transform=\"pandas\")\n    X_train_guess = tgb.fit_transform(X_train_res.copy(), y_train_res.copy())\n    X_test_guess = tgb.transform(X_test.copy())\n\n    gbdt_ref = GradientBoostingClassifier(n_estimators=60, max_depth=3, random_state=SEED)\n    gbdt_ref.fit(X_train_guess, y_train_res)\n    warm_labels = gbdt_ref.predict(X_train_guess)\n\n    clf_guess = GOSDTClassifier(regularization=0.001, depth_budget=3, time_limit=1800)\n\n    start_train = time.time()\n    clf_guess.fit(X_train_guess, y_train_res, y_ref=warm_labels)\n    end_train = time.time()\n    times[\"GOSDT_Guessed\"][\"train_time\"].append(end_train - start_train)\n\n    start_test = time.time()\n    y_pred_test_g = clf_guess.predict(X_test_guess)\n    end_test = time.time()\n    times[\"GOSDT_Guessed\"][\"test_time\"].append(end_test - start_test)\n\n    y_pred_train_g = clf_guess.predict(X_train_guess)\n\n    metrics[\"GOSDT_Guessed\"][\"train_acc\"].append(accuracy_score(y_train_res, y_pred_train_g))\n    metrics[\"GOSDT_Guessed\"][\"test_acc\"].append(accuracy_score(y_test, y_pred_test_g))\n\n    # -------- GOSDT with NumericBinarizer --------\n    print(\"-> GOSDT (NumericBinarizer)\")\n    nb = NumericBinarizer()\n    nb.set_output(transform=\"pandas\")\n    X_train_num = nb.fit_transform(X_train_res.copy(), y_train_res.copy())\n    X_test_num = nb.transform(X_test.copy())\n\n    clf_num = GOSDTClassifier(regularization=0.001, depth_budget=3, time_limit=1800)\n\n    start_train = time.time()\n    clf_num.fit(X_train_num, y_train_res)\n    end_train = time.time()\n    times[\"GOSDT_Numerical\"][\"train_time\"].append(end_train - start_train)\n\n    start_test = time.time()\n    y_pred_test_n = clf_num.predict(X_test_num)\n    end_test = time.time()\n    times[\"GOSDT_Numerical\"][\"test_time\"].append(end_test - start_test)\n\n    y_pred_train_n = clf_num.predict(X_train_num)\n\n    metrics[\"GOSDT_Numerical\"][\"train_acc\"].append(accuracy_score(y_train_res, y_pred_train_n))\n    metrics[\"GOSDT_Numerical\"][\"test_acc\"].append(accuracy_score(y_test, y_pred_test_n))\n\n    # -------- GBDT Baseline --------\n    print(\"-> GBDT Baseline\")\n    gbdt = GradientBoostingClassifier(n_estimators=60, max_depth=3,random_state=SEED)\n\n    start_train = time.time()\n    gbdt.fit(X_train_res, y_train_res)\n    end_train = time.time()\n    times[\"GBDT_Baseline\"][\"train_time\"].append(end_train - start_train)\n\n    start_test = time.time()\n    y_pred_test_b = gbdt.predict(X_test)\n    end_test = time.time()\n    times[\"GBDT_Baseline\"][\"test_time\"].append(end_test - start_test)\n\n    y_pred_train_b = gbdt.predict(X_train_res)\n\n    metrics[\"GBDT_Baseline\"][\"train_acc\"].append(accuracy_score(y_train_res, y_pred_train_b))\n    metrics[\"GBDT_Baseline\"][\"test_acc\"].append(accuracy_score(y_test, y_pred_test_b))\n\n# ------------------ Accuracy Results ------------------\nprint(\"\\n=== Median Accuracy Results Over Folds ===\")\nfor model in metrics:\n    print(f\"\\n{model}:\")\n    print(f\"  Median Train Accuracy: {np.median(metrics[model]['train_acc']):.4f}\")\n    print(f\"  Median Test Accuracy:  {np.median(metrics[model]['test_acc']):.4f}\")\n\n# ------------------ Timing Results ------------------\nprint(\"\\n=== Median Training & Testing Time (seconds) ===\")\nfor model in times:\n    print(f\"\\n{model}:\")\n    print(f\"  Median Train Time: {np.median(times[model]['train_time']):.2f} sec\")\n    print(f\"  Median Test Time:  {np.median(times[model]['test_time']):.4f} sec\")\n\n# ------------------ Optional: Plot Accuracy ------------------\nlabels = list(metrics.keys())\nmedian_test_accuracies = [np.median(metrics[m][\"test_acc\"]) for m in labels]\n\nplt.figure(figsize=(8, 5))\nbars = plt.bar(labels, median_test_accuracies, color=[\"cornflowerblue\", \"lightcoral\", \"lightgreen\"])\nplt.ylabel(\"Median Test Accuracy\")\nplt.title(\"APH Dataset: GOSDT vs GBDT (SMOTE + Stratified KFold)\")\nfor bar in bars:\n    yval = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2.0, yval, f'{yval:.3f}', va='bottom', ha='center')\nplt.xticks(rotation=15)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install gosdt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T17:29:53.513679Z","iopub.execute_input":"2025-06-15T17:29:53.514036Z","iopub.status.idle":"2025-06-15T17:29:57.761678Z","shell.execute_reply.started":"2025-06-15T17:29:53.514010Z","shell.execute_reply":"2025-06-15T17:29:57.760511Z"}},"outputs":[{"name":"stdout","text":"Collecting gosdt\n  Downloading gosdt-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nRequirement already satisfied: numpy>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from gosdt) (1.24.4)\nRequirement already satisfied: scikit-learn>=1.2.2 in /usr/local/lib/python3.11/dist-packages (from gosdt) (1.3.2)\nRequirement already satisfied: pandas>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from gosdt) (2.2.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.1->gosdt) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.1->gosdt) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.1->gosdt) (2025.2)\nRequirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.2->gosdt) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.2->gosdt) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.2->gosdt) (3.6.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.1->gosdt) (1.17.0)\nDownloading gosdt-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: gosdt\nSuccessfully installed gosdt-1.0.4\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# mAIN","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport time\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier, export_text\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom imblearn.over_sampling import SMOTE\nfrom gosdt import GOSDTClassifier, ThresholdGuessBinarizer, NumericBinarizer\n\n# Load Antepartum Hemorrhage data\n# df = pd.read_csv(\"/content/aph.csv\")  # Uncomment and update the path if needed\n# X, y = df.iloc[:, :-1], df.iloc[:, -1]\n\n# Set random seed and Stratified KFold\nSEED = 42\nskf = StratifiedKFold(n_splits=2, shuffle=True, random_state=SEED)\n\n# Initialize metrics and times dictionaries\nmetrics = {\n    \"GOSDT_Guessed\": {\"train_acc\": [], \"test_acc\": [], \"train_time\": [], \"test_time\": []},\n    \"GOSDT_Numerical\": {\"train_acc\": [], \"test_acc\": [], \"train_time\": [], \"test_time\": []},\n    \"GBDT_Baseline\": {\"train_acc\": [], \"test_acc\": [], \"train_time\": [], \"test_time\": [], \"n_leaves\": []},\n    \"CART\": {\"train_acc\": [], \"test_acc\": [], \"train_time\": [], \"test_time\": [], \"n_leaves\": []},\n}\n\nfor fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n    print(f\"\\n=== Fold {fold + 1} ===\")\n\n    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n\n    # SMOTE on training data only\n    smote = SMOTE(random_state=SEED, sampling_strategy=1)\n    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n\n    # -------- GOSDT with ThresholdGuessBinarizer --------\n    print(\"-> GOSDT (ThresholdGuessBinarizer + y_ref)\")\n    tgb = ThresholdGuessBinarizer(n_estimators=200, max_depth=1, random_state=SEED)\n    tgb.set_output(transform=\"pandas\")\n    X_train_guess = tgb.fit_transform(X_train_res.copy(), y_train_res.copy())\n    X_test_guess = tgb.transform(X_test.copy())\n\n    gbdt_ref = GradientBoostingClassifier(n_estimators=60, max_depth=1, random_state=SEED)\n    gbdt_ref.fit(X_train_guess, y_train_res)\n    warm_labels = gbdt_ref.predict(X_train_guess)\n\n    clf_guess = GOSDTClassifier(regularization=0.001, depth_budget=1, time_limit=1800)\n\n    start_train = time.time()\n    clf_guess.fit(X_train_guess, y_train_res, y_ref=warm_labels)\n    end_train = time.time()\n    metrics[\"GOSDT_Guessed\"][\"train_time\"].append(end_train - start_train)\n\n    start_test = time.time()\n    y_pred_test_g = clf_guess.predict(X_test_guess)\n    end_test = time.time()\n    metrics[\"GOSDT_Guessed\"][\"test_time\"].append(end_test - start_test)\n\n    y_pred_train_g = clf_guess.predict(X_train_guess)\n\n    metrics[\"GOSDT_Guessed\"][\"train_acc\"].append(accuracy_score(y_train_res, y_pred_train_g))\n    metrics[\"GOSDT_Guessed\"][\"test_acc\"].append(accuracy_score(y_test, y_pred_test_g))\n\n    print(f\"Training accuracy: {clf_guess.score(X_train_guess, y_train_res):.4f}\")\n    for i, tree in enumerate(clf_guess.trees_):\n        print(f\"Tree {i + 1}:\")\n        print(tree)\n\n    # -------- GOSDT with NumericBinarizer --------\n    print(\"-> GOSDT (NumericBinarizer)\")\n    nb = NumericBinarizer()\n    nb.set_output(transform=\"pandas\")\n    X_train_num = nb.fit_transform(X_train_res.copy(), y_train_res.copy())\n    X_test_num = nb.transform(X_test.copy())\n\n    clf_num = GOSDTClassifier(regularization=0.001, depth_budget=1, time_limit=1800)\n\n    start_train = time.time()\n    clf_num.fit(X_train_num, y_train_res)\n    end_train = time.time()\n    metrics[\"GOSDT_Numerical\"][\"train_time\"].append(end_train - start_train)\n\n    start_test = time.time()\n    y_pred_test_n = clf_num.predict(X_test_num)\n    end_test = time.time()\n    metrics[\"GOSDT_Numerical\"][\"test_time\"].append(end_test - start_test)\n\n    y_pred_train_n = clf_num.predict(X_train_num)\n\n    metrics[\"GOSDT_Numerical\"][\"train_acc\"].append(accuracy_score(y_train_res, y_pred_train_n))\n    metrics[\"GOSDT_Numerical\"][\"test_acc\"].append(accuracy_score(y_test, y_pred_test_n))\n\n    print(f\"Training accuracy: {clf_num.score(X_train_num, y_train_res):.4f}\")\n    for i, tree in enumerate(clf_num.trees_):\n        print(f\"Tree {i + 1}:\")\n        print(tree)\n\n    # -------- GBDT Baseline --------\n    print(\"-> GBDT Baseline\")\n    gbdt = GradientBoostingClassifier(n_estimators=60, max_depth=1, random_state=SEED)\n\n    start_train = time.time()\n    gbdt.fit(X_train_res, y_train_res)\n    end_train = time.time()\n    metrics[\"GBDT_Baseline\"][\"train_time\"].append(end_train - start_train)\n\n    start_test = time.time()\n    y_pred_test_b = gbdt.predict(X_test)\n    end_test = time.time()\n    metrics[\"GBDT_Baseline\"][\"test_time\"].append(end_test - start_test)\n\n    y_pred_train_b = gbdt.predict(X_train_res)\n\n    # Calculate total number of leaves across all trees\n    n_leaves = sum(tree.tree_.n_leaves for est in gbdt.estimators_ for tree in est)\n    metrics[\"GBDT_Baseline\"][\"n_leaves\"].append(n_leaves)\n\n    metrics[\"GBDT_Baseline\"][\"train_acc\"].append(accuracy_score(y_train_res, y_pred_train_b))\n    metrics[\"GBDT_Baseline\"][\"test_acc\"].append(accuracy_score(y_test, y_pred_test_b))\n\n    print(f\"Training accuracy: {gbdt.score(X_train_res, y_train_res):.4f}\")\n    print(f\"Number of leaves: {n_leaves}\")\n    # Print first 5 GBDT trees for inspection\n    feature_names = X.columns\n    for i, tree in enumerate(sum(gbdt.estimators_, [])):\n        #if i < 5:\n            print(f\"GBDT Tree {i + 1}:\")\n            tree_str = export_text(tree, feature_names=feature_names)\n            print(tree_str)\n\n    # -------- CART --------\n    print(\"-> CART\")\n    cart = DecisionTreeClassifier(random_state=SEED)  # Aligned with GOSDT depth_budget\n\n    start_train = time.time()\n    cart.fit(X_train_res, y_train_res)\n    end_train = time.time()\n    metrics[\"CART\"][\"train_time\"].append(end_train - start_train)\n\n    start_test = time.time()\n    y_pred_test_c = cart.predict(X_test)\n    end_test = time.time()\n    metrics[\"CART\"][\"test_time\"].append(end_test - start_test)\n\n    y_pred_train_c = cart.predict(X_train_res)\n\n    # Calculate number of leaves for CART\n    n_leaves = cart.tree_.n_leaves\n    metrics[\"CART\"][\"n_leaves\"].append(n_leaves)\n\n    metrics[\"CART\"][\"train_acc\"].append(accuracy_score(y_train_res, y_pred_train_c))\n    metrics[\"CART\"][\"test_acc\"].append(accuracy_score(y_test, y_pred_test_c))\n\n    print(f\"Training accuracy: {cart.score(X_train_res, y_train_res):.4f}\")\n    print(f\"Number of leaves: {n_leaves}\")\n    print(\"CART Tree:\")\n    tree_str = export_text(cart, feature_names=X.columns)\n    print(tree_str)\n\n# ------------------ Results ------------------\nprint(\"\\n=== Average Results Over 5 Folds ===\")\nfor model in metrics:\n    print(f\"\\n{model}:\")\n    print(f\"  Average Train Accuracy: {np.mean(metrics[model]['train_acc']):.4f}\")\n    print(f\"  Average Test Accuracy:  {np.mean(metrics[model]['test_acc']):.4f}\")\n    print(f\"  Average Train Time:     {np.mean(metrics[model]['train_time']):.4f}s\")\n    print(f\"  Average Test Time:      {np.mean(metrics[model]['test_time']):.4f}s\")\n    if \"n_leaves\" in metrics[model]:\n        print(f\"  Average Number of Leaves: {np.mean(metrics[model]['n_leaves']):.0f}\")\n\n# ------------------ Plot Accuracy ------------------\nlabels = list(metrics.keys())\ntest_accuracies = [np.mean(metrics[m][\"test_acc\"]) for m in labels]\ntrain_times = [np.mean(metrics[m][\"train_time\"]) for m in labels]\n\nplt.figure(figsize=(12, 4))\n# Plot: Accuracy\nplt.subplot(1, 2, 1)\nbars = plt.bar(labels, test_accuracies, color=[\"cornflowerblue\", \"lightcoral\", \"lightgreen\", \"lightgoldenrodyellow\"])\nplt.ylabel(\"Average Test Accuracy\")\nplt.title(\"APH Dataset: GOSDT vs GBDT vs CART (SMOTE + Stratified KFold)\")\nfor bar, acc in zip(bars, test_accuracies):\n    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f\"{acc:.4f}\", ha='center', va='bottom')\nplt.xticks(rotation=15)\n\n# Plot: Training Time (log scale)\nplt.subplot(1, 2, 2)\nbars = plt.bar(labels, train_times, color=[\"cornflowerblue\", \"lightcoral\", \"lightgreen\", \"lightgoldenrodyellow\"])\nplt.yscale(\"log\")\nplt.ylabel(\"Train Time (s, log scale)\")\nplt.title(\"Average Training Time\")\nfor bar, time_val in zip(bars, train_times):\n    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f\"{time_val:.2f}\", ha='center', va='bottom')\nplt.xticks(rotation=15)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-15T18:28:14.108090Z","iopub.execute_input":"2025-06-15T18:28:14.108666Z","iopub.status.idle":"2025-06-15T18:28:36.465386Z","shell.execute_reply.started":"2025-06-15T18:28:14.108637Z","shell.execute_reply":"2025-06-15T18:28:36.464014Z"}},"outputs":[{"name":"stdout","text":"\n=== Fold 1 ===\n-> GOSDT (ThresholdGuessBinarizer + y_ref)\nTraining accuracy: 0.6492\nTree 1:\n<class 'gosdt._tree.Tree'>: { feature: 43 [ left child: { prediction: 1, loss: 0.2034417688846588 }, right child: { prediction: 0, loss: 0.14733615517616272 }] }, Index(['PW_AGE <= 36.5', 'PW_AGE <= 37.5', 'PREV_SB <= 0.0006768128369003534',\n       'PREV_SB <= 0.9999941885471344', 'PREV_MIS <= 6.734650378348306e-05',\n       'PREV_MIS <= 0.9999941885471344', 'PREV_MULTIP <= 0.004431642591953278',\n       'PREV_CS <= 0.9997068643569946', 'GRAVIDITY <= 1.0001347064971924',\n       'GRAVIDITY <= 4.996511459350586', 'GRAVIDITY <= 9.994819164276123',\n       'PARITY <= 1.0006768107414246', 'PARITY <= 2.0022811889648438',\n       'SBP1 <= 119.99937438964844', 'DBP1 <= 62.00140953063965',\n       'DBP1 <= 75.99517440795898', 'UDIP_PROT1 <= 0.0014738220488652587',\n       'UDIP_PROT1 <= 1.998007893562317', 'SBP2 <= 94.98472213745117',\n       'SBP2 <= 110.00522994995117', 'SBP2 <= 117.99419021606445',\n       'SBP2 <= 118.99233627319336', 'DBP2 <= 62.00383186340332',\n       'DBP2 <= 63.006582260131836', 'DBP2 <= 67.00187301635742',\n       'DBP2 <= 68.00176620483398', 'DBP2 <= 70.99669647216797',\n       'DBP2 <= 73.99784851074219', 'DBP2 <= 74.99896621704102',\n       'DBP2 <= 77.99110794067383', 'UDIP_PROT2 <= 0.003666084026917815',\n       'UDIP_PROT2 <= 1.998347520828247', 'SBP3 <= 112.01476669311523',\n       'SBP3 <= 115.00080490112305', 'SBP3 <= 115.99917221069336',\n       'SBP3 <= 141.5', 'DBP3 <= 63.01830291748047',\n       'DBP3 <= 65.00756454467773', 'DBP3 <= 68.0000228881836',\n       'UDIP_PROT3 <= 0.0005862742546014488',\n       'UDIP_PROT3 <= 1.9984349012374878', 'DBP4 <= 68.01272201538086',\n       'DBP4 <= 70.00281143188477', 'DBP4 <= 73.99908065795898',\n       'UDIP_PROT4 <= 0.0061516109853982925',\n       'MAT_WEIGHT <= 58.912593841552734', 'MAT_WEIGHT <= 59.01502799987793',\n       'MAT_WEIGHT <= 60.318519592285156', 'MAT_WEIGHT <= 74.3914680480957',\n       'SBP4 <= 103.01773834228516'],\n      dtype='object'), 2\n-> GOSDT (NumericBinarizer)\nTraining accuracy: 0.6492\nTree 1:\n<class 'gosdt._tree.Tree'>: { feature: 19283 [ left child: { prediction: 1, loss: 0.2034417688846588 }, right child: { prediction: 0, loss: 0.14733615517616272 }] }, Index(['PW_AGE <= 18.5', 'PW_AGE <= 19.5', 'PW_AGE <= 20.5', 'PW_AGE <= 21.5',\n       'PW_AGE <= 22.5', 'PW_AGE <= 23.5', 'PW_AGE <= 24.5', 'PW_AGE <= 25.5',\n       'PW_AGE <= 26.5', 'PW_AGE <= 27.5',\n       ...\n       'MAT_WEIGHT <= 109.94999999999999', 'MAT_WEIGHT <= 110.19999999999999',\n       'MAT_WEIGHT <= 111.44999999999999', 'MAT_WEIGHT <= 112.85',\n       'MAT_WEIGHT <= 113.25', 'MAT_WEIGHT <= 113.65', 'MAT_WEIGHT <= 115.1',\n       'MAT_WEIGHT <= 117.8', 'MAT_WEIGHT <= 119.4', 'LABOUR_24_1.0 <= 0.5'],\n      dtype='object', length=22568), 2\n-> GBDT Baseline\nTraining accuracy: 0.8102\nNumber of leaves: 120\n-> CART\nTraining accuracy: 1.0000\nNumber of leaves: 207\nCART Tree:\n|--- DBP4 <= 74.00\n|   |--- DBP4 <= 70.00\n|   |   |--- PARITY <= 3.99\n|   |   |   |--- PARITY <= 3.00\n|   |   |   |   |--- SBP2 <= 118.87\n|   |   |   |   |   |--- SBP2 <= 110.01\n|   |   |   |   |   |   |--- GRAVIDITY <= 3.01\n|   |   |   |   |   |   |   |--- PARITY <= 2.12\n|   |   |   |   |   |   |   |   |--- SBP2 <= 109.50\n|   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |--- SBP2 >  109.50\n|   |   |   |   |   |   |   |   |   |--- SBP4 <= 101.00\n|   |   |   |   |   |   |   |   |   |   |--- MAT_WEIGHT <= 46.95\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |   |   |--- MAT_WEIGHT >  46.95\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |   |--- SBP4 >  101.00\n|   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |--- PARITY >  2.12\n|   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |--- GRAVIDITY >  3.01\n|   |   |   |   |   |   |   |--- GRAVIDITY <= 4.00\n|   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |--- GRAVIDITY >  4.00\n|   |   |   |   |   |   |   |   |--- PARITY <= 1.69\n|   |   |   |   |   |   |   |   |   |--- UDIP_PROT1 <= 1.02\n|   |   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |   |--- UDIP_PROT1 >  1.02\n|   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |--- PARITY >  1.69\n|   |   |   |   |   |   |   |   |   |--- UDIP_PROT1 <= 0.17\n|   |   |   |   |   |   |   |   |   |   |--- MAT_WEIGHT <= 45.70\n|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n|   |   |   |   |   |   |   |   |   |   |--- MAT_WEIGHT >  45.70\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |   |--- UDIP_PROT1 >  0.17\n|   |   |   |   |   |   |   |   |   |   |--- SBP2 <= 101.89\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |   |   |--- SBP2 >  101.89\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |--- SBP2 >  110.01\n|   |   |   |   |   |   |--- PW_AGE <= 26.50\n|   |   |   |   |   |   |   |--- MAT_WEIGHT <= 48.11\n|   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |--- MAT_WEIGHT >  48.11\n|   |   |   |   |   |   |   |   |--- PW_AGE <= 18.50\n|   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |--- PW_AGE >  18.50\n|   |   |   |   |   |   |   |   |   |--- DBP2 <= 63.03\n|   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |   |--- DBP2 >  63.03\n|   |   |   |   |   |   |   |   |   |   |--- DBP4 <= 70.00\n|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 12\n|   |   |   |   |   |   |   |   |   |   |--- DBP4 >  70.00\n|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n|   |   |   |   |   |   |--- PW_AGE >  26.50\n|   |   |   |   |   |   |   |--- PARITY <= 2.30\n|   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |--- PARITY >  2.30\n|   |   |   |   |   |   |   |   |--- PARITY <= 2.98\n|   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |--- PARITY >  2.98\n|   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |--- SBP2 >  118.87\n|   |   |   |   |   |--- class: 0.0\n|   |   |   |--- PARITY >  3.00\n|   |   |   |   |--- class: 1.0\n|   |   |--- PARITY >  3.99\n|   |   |   |--- DBP3 <= 73.06\n|   |   |   |   |--- SBP3 <= 122.33\n|   |   |   |   |   |--- SBP2 <= 132.79\n|   |   |   |   |   |   |--- MAT_WEIGHT <= 47.95\n|   |   |   |   |   |   |   |--- MAT_WEIGHT <= 47.80\n|   |   |   |   |   |   |   |   |--- SBP3 <= 115.40\n|   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |--- SBP3 >  115.40\n|   |   |   |   |   |   |   |   |   |--- SBP3 <= 117.59\n|   |   |   |   |   |   |   |   |   |   |--- DBP1 <= 66.86\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |   |   |--- DBP1 >  66.86\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |   |--- SBP3 >  117.59\n|   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |--- MAT_WEIGHT >  47.80\n|   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |--- MAT_WEIGHT >  47.95\n|   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |--- SBP2 >  132.79\n|   |   |   |   |   |   |--- SBP3 <= 113.95\n|   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |--- SBP3 >  113.95\n|   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |--- SBP3 >  122.33\n|   |   |   |   |   |--- UDIP_PROT1 <= 0.19\n|   |   |   |   |   |   |--- PW_AGE <= 23.50\n|   |   |   |   |   |   |   |--- MAT_WEIGHT <= 59.33\n|   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |--- MAT_WEIGHT >  59.33\n|   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |--- PW_AGE >  23.50\n|   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |--- UDIP_PROT1 >  0.19\n|   |   |   |   |   |   |--- DBP3 <= 68.00\n|   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |--- DBP3 >  68.00\n|   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |--- DBP3 >  73.06\n|   |   |   |   |--- DBP1 <= 73.91\n|   |   |   |   |   |--- SBP1 <= 110.03\n|   |   |   |   |   |   |--- UDIP_PROT1 <= 0.04\n|   |   |   |   |   |   |   |--- DBP2 <= 85.50\n|   |   |   |   |   |   |   |   |--- SBP4 <= 99.00\n|   |   |   |   |   |   |   |   |   |--- SBP2 <= 109.00\n|   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |   |--- SBP2 >  109.00\n|   |   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |--- SBP4 >  99.00\n|   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |--- DBP2 >  85.50\n|   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |--- UDIP_PROT1 >  0.04\n|   |   |   |   |   |   |   |--- UDIP_PROT1 <= 1.96\n|   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |--- UDIP_PROT1 >  1.96\n|   |   |   |   |   |   |   |   |--- DBP1 <= 71.50\n|   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |--- DBP1 >  71.50\n|   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |--- SBP1 >  110.03\n|   |   |   |   |   |   |--- MAT_WEIGHT <= 66.56\n|   |   |   |   |   |   |   |--- SBP4 <= 105.84\n|   |   |   |   |   |   |   |   |--- PREV_MIS <= 0.39\n|   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |--- PREV_MIS >  0.39\n|   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |--- SBP4 >  105.84\n|   |   |   |   |   |   |   |   |--- PW_AGE <= 25.50\n|   |   |   |   |   |   |   |   |   |--- DBP4 <= 68.50\n|   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |   |--- DBP4 >  68.50\n|   |   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |--- PW_AGE >  25.50\n|   |   |   |   |   |   |   |   |   |--- SBP4 <= 122.94\n|   |   |   |   |   |   |   |   |   |   |--- DBP3 <= 87.44\n|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 7\n|   |   |   |   |   |   |   |   |   |   |--- DBP3 >  87.44\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |   |--- SBP4 >  122.94\n|   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |--- MAT_WEIGHT >  66.56\n|   |   |   |   |   |   |   |--- UDIP_PROT4 <= 1.00\n|   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |--- UDIP_PROT4 >  1.00\n|   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |--- DBP1 >  73.91\n|   |   |   |   |   |--- SBP4 <= 129.50\n|   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |--- SBP4 >  129.50\n|   |   |   |   |   |   |--- class: 1.0\n|   |--- DBP4 >  70.00\n|   |   |--- DBP3 <= 70.00\n|   |   |   |--- DBP2 <= 65.25\n|   |   |   |   |--- DBP4 <= 73.25\n|   |   |   |   |   |--- PREV_SB <= 0.28\n|   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |--- PREV_SB >  0.28\n|   |   |   |   |   |   |--- PARITY <= 2.57\n|   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |--- PARITY >  2.57\n|   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |--- DBP4 >  73.25\n|   |   |   |   |   |--- class: 1.0\n|   |   |   |--- DBP2 >  65.25\n|   |   |   |   |--- MAT_WEIGHT <= 59.86\n|   |   |   |   |   |--- SBP3 <= 111.34\n|   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |--- SBP3 >  111.34\n|   |   |   |   |   |   |--- DBP2 <= 71.00\n|   |   |   |   |   |   |   |--- SBP1 <= 114.81\n|   |   |   |   |   |   |   |   |--- MAT_WEIGHT <= 58.05\n|   |   |   |   |   |   |   |   |   |--- DBP3 <= 62.22\n|   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |   |--- DBP3 >  62.22\n|   |   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |--- MAT_WEIGHT >  58.05\n|   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |--- SBP1 >  114.81\n|   |   |   |   |   |   |   |   |--- PARITY <= 2.64\n|   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |--- PARITY >  2.64\n|   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |--- DBP2 >  71.00\n|   |   |   |   |   |   |   |--- SBP4 <= 105.50\n|   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |--- SBP4 >  105.50\n|   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |--- MAT_WEIGHT >  59.86\n|   |   |   |   |   |--- MAT_WEIGHT <= 71.41\n|   |   |   |   |   |   |--- SBP2 <= 121.00\n|   |   |   |   |   |   |   |--- SBP1 <= 119.65\n|   |   |   |   |   |   |   |   |--- DBP2 <= 67.04\n|   |   |   |   |   |   |   |   |   |--- PARITY <= 3.50\n|   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |   |--- PARITY >  3.50\n|   |   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |--- DBP2 >  67.04\n|   |   |   |   |   |   |   |   |   |--- PREV_SB <= 0.99\n|   |   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |   |--- PREV_SB >  0.99\n|   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |--- SBP1 >  119.65\n|   |   |   |   |   |   |   |   |--- SBP3 <= 114.02\n|   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |--- SBP3 >  114.02\n|   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |--- SBP2 >  121.00\n|   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |--- MAT_WEIGHT >  71.41\n|   |   |   |   |   |   |--- class: 0.0\n|   |   |--- DBP3 >  70.00\n|   |   |   |--- SBP4 <= 116.00\n|   |   |   |   |--- UDIP_PROT3 <= 0.16\n|   |   |   |   |   |--- DBP4 <= 70.98\n|   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |--- DBP4 >  70.98\n|   |   |   |   |   |   |--- DBP3 <= 70.74\n|   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |--- DBP3 >  70.74\n|   |   |   |   |   |   |   |--- SBP3 <= 122.95\n|   |   |   |   |   |   |   |   |--- PARITY <= 7.50\n|   |   |   |   |   |   |   |   |   |--- UDIP_PROT2 <= 0.28\n|   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |   |--- UDIP_PROT2 >  0.28\n|   |   |   |   |   |   |   |   |   |   |--- UDIP_PROT2 <= 1.28\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |   |   |--- UDIP_PROT2 >  1.28\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |--- PARITY >  7.50\n|   |   |   |   |   |   |   |   |   |--- SBP1 <= 111.50\n|   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |   |--- SBP1 >  111.50\n|   |   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |--- SBP3 >  122.95\n|   |   |   |   |   |   |   |   |--- DBP1 <= 66.48\n|   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |--- DBP1 >  66.48\n|   |   |   |   |   |   |   |   |   |--- DBP4 <= 71.01\n|   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |   |--- DBP4 >  71.01\n|   |   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |--- UDIP_PROT3 >  0.16\n|   |   |   |   |   |--- UDIP_PROT3 <= 1.99\n|   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |--- UDIP_PROT3 >  1.99\n|   |   |   |   |   |   |--- SBP4 <= 105.00\n|   |   |   |   |   |   |   |--- SBP3 <= 112.50\n|   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |--- SBP3 >  112.50\n|   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |--- SBP4 >  105.00\n|   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |--- SBP4 >  116.00\n|   |   |   |   |--- PW_AGE <= 35.50\n|   |   |   |   |   |--- UDIP_PROT2 <= 2.00\n|   |   |   |   |   |   |--- PREV_CS <= 1.00\n|   |   |   |   |   |   |   |--- DBP1 <= 62.03\n|   |   |   |   |   |   |   |   |--- DBP3 <= 73.00\n|   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |--- DBP3 >  73.00\n|   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |--- DBP1 >  62.03\n|   |   |   |   |   |   |   |   |--- SINGLE_TWIN <= 1.92\n|   |   |   |   |   |   |   |   |   |--- DBP2 <= 74.91\n|   |   |   |   |   |   |   |   |   |   |--- LABOUR_24_1.0 <= 0.50\n|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 8\n|   |   |   |   |   |   |   |   |   |   |--- LABOUR_24_1.0 >  0.50\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |   |--- DBP2 >  74.91\n|   |   |   |   |   |   |   |   |   |   |--- SBP2 <= 119.59\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |   |   |--- SBP2 >  119.59\n|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n|   |   |   |   |   |   |   |   |--- SINGLE_TWIN >  1.92\n|   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |--- PREV_CS >  1.00\n|   |   |   |   |   |   |   |--- SBP4 <= 118.50\n|   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |--- SBP4 >  118.50\n|   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |--- UDIP_PROT2 >  2.00\n|   |   |   |   |   |   |--- UDIP_PROT1 <= 0.54\n|   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |--- UDIP_PROT1 >  0.54\n|   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |--- PW_AGE >  35.50\n|   |   |   |   |   |--- UDIP_PROT1 <= 0.34\n|   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |--- UDIP_PROT1 >  0.34\n|   |   |   |   |   |   |--- class: 1.0\n|--- DBP4 >  74.00\n|   |--- DBP4 <= 74.00\n|   |   |--- DBP1 <= 94.50\n|   |   |   |--- class: 0.0\n|   |   |--- DBP1 >  94.50\n|   |   |   |--- MAT_WEIGHT <= 87.70\n|   |   |   |   |--- class: 0.0\n|   |   |   |--- MAT_WEIGHT >  87.70\n|   |   |   |   |--- class: 1.0\n|   |--- DBP4 >  74.00\n|   |   |--- GRAVIDITY <= 1.01\n|   |   |   |--- SBP2 <= 145.50\n|   |   |   |   |--- SBP1 <= 90.50\n|   |   |   |   |   |--- class: 1.0\n|   |   |   |   |--- SBP1 >  90.50\n|   |   |   |   |   |--- PW_AGE <= 37.50\n|   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |--- PW_AGE >  37.50\n|   |   |   |   |   |   |--- MAT_WEIGHT <= 63.15\n|   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |--- MAT_WEIGHT >  63.15\n|   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |--- SBP2 >  145.50\n|   |   |   |   |--- class: 1.0\n|   |   |--- GRAVIDITY >  1.01\n|   |   |   |--- PARITY <= 2.01\n|   |   |   |   |--- PREV_SB <= 0.17\n|   |   |   |   |   |--- SBP2 <= 95.06\n|   |   |   |   |   |   |--- MAT_WEIGHT <= 46.96\n|   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |--- MAT_WEIGHT >  46.96\n|   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |--- SBP2 >  95.06\n|   |   |   |   |   |   |--- GRAVIDITY <= 1.99\n|   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |--- GRAVIDITY >  1.99\n|   |   |   |   |   |   |   |--- UDIP_PROT2 <= 0.46\n|   |   |   |   |   |   |   |   |--- DBP4 <= 74.91\n|   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |--- DBP4 >  74.91\n|   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |--- UDIP_PROT2 >  0.46\n|   |   |   |   |   |   |   |   |--- MAT_WEIGHT <= 47.25\n|   |   |   |   |   |   |   |   |   |--- SBP1 <= 114.55\n|   |   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |   |--- SBP1 >  114.55\n|   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |--- MAT_WEIGHT >  47.25\n|   |   |   |   |   |   |   |   |   |--- UDIP_PROT4 <= 1.00\n|   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |   |--- UDIP_PROT4 >  1.00\n|   |   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |--- PREV_SB >  0.17\n|   |   |   |   |   |--- DBP1 <= 69.99\n|   |   |   |   |   |   |--- MAT_WEIGHT <= 72.22\n|   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |--- MAT_WEIGHT >  72.22\n|   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |--- DBP1 >  69.99\n|   |   |   |   |   |   |--- class: 0.0\n|   |   |   |--- PARITY >  2.01\n|   |   |   |   |--- GRAVIDITY <= 4.00\n|   |   |   |   |   |--- class: 1.0\n|   |   |   |   |--- GRAVIDITY >  4.00\n|   |   |   |   |   |--- UDIP_PROT1 <= 0.00\n|   |   |   |   |   |   |--- PW_AGE <= 36.50\n|   |   |   |   |   |   |   |--- UDIP_PROT2 <= 0.01\n|   |   |   |   |   |   |   |   |--- DBP4 <= 86.99\n|   |   |   |   |   |   |   |   |   |--- SBP4 <= 135.17\n|   |   |   |   |   |   |   |   |   |   |--- DBP3 <= 85.04\n|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 9\n|   |   |   |   |   |   |   |   |   |   |--- DBP3 >  85.04\n|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 7\n|   |   |   |   |   |   |   |   |   |--- SBP4 >  135.17\n|   |   |   |   |   |   |   |   |   |   |--- PARITY <= 3.96\n|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n|   |   |   |   |   |   |   |   |   |   |--- PARITY >  3.96\n|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 4\n|   |   |   |   |   |   |   |   |--- DBP4 >  86.99\n|   |   |   |   |   |   |   |   |   |--- SBP2 <= 146.87\n|   |   |   |   |   |   |   |   |   |   |--- PW_AGE <= 24.50\n|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n|   |   |   |   |   |   |   |   |   |   |--- PW_AGE >  24.50\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |   |--- SBP2 >  146.87\n|   |   |   |   |   |   |   |   |   |   |--- SBP4 <= 136.00\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |   |   |--- SBP4 >  136.00\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |--- UDIP_PROT2 >  0.01\n|   |   |   |   |   |   |   |   |--- UDIP_PROT2 <= 1.99\n|   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |--- UDIP_PROT2 >  1.99\n|   |   |   |   |   |   |   |   |   |--- MAT_WEIGHT <= 46.44\n|   |   |   |   |   |   |   |   |   |   |--- MAT_WEIGHT <= 44.90\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |   |   |--- MAT_WEIGHT >  44.90\n|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n|   |   |   |   |   |   |   |   |   |--- MAT_WEIGHT >  46.44\n|   |   |   |   |   |   |   |   |   |   |--- SBP3 <= 109.10\n|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n|   |   |   |   |   |   |   |   |   |   |--- SBP3 >  109.10\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |--- PW_AGE >  36.50\n|   |   |   |   |   |   |   |--- SBP4 <= 149.00\n|   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |--- SBP4 >  149.00\n|   |   |   |   |   |   |   |   |--- DBP2 <= 64.50\n|   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |--- DBP2 >  64.50\n|   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |--- UDIP_PROT1 >  0.00\n|   |   |   |   |   |   |--- UDIP_PROT1 <= 2.00\n|   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |--- UDIP_PROT1 >  2.00\n|   |   |   |   |   |   |   |--- SBP3 <= 127.50\n|   |   |   |   |   |   |   |   |--- DBP4 <= 74.97\n|   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |--- DBP4 >  74.97\n|   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |--- SBP3 >  127.50\n|   |   |   |   |   |   |   |   |--- SBP3 <= 141.50\n|   |   |   |   |   |   |   |   |   |--- GRAVIDITY <= 6.00\n|   |   |   |   |   |   |   |   |   |   |--- PREV_MIS <= 1.50\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |   |   |--- PREV_MIS >  1.50\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |   |--- GRAVIDITY >  6.00\n|   |   |   |   |   |   |   |   |   |   |--- UDIP_PROT2 <= 1.00\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |   |   |--- UDIP_PROT2 >  1.00\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |--- SBP3 >  141.50\n|   |   |   |   |   |   |   |   |   |--- class: 0.0\n\n\n=== Fold 2 ===\n-> GOSDT (ThresholdGuessBinarizer + y_ref)\nTraining accuracy: 0.6675\nTree 1:\n<class 'gosdt._tree.Tree'>: { feature: 36 [ left child: { prediction: 1, loss: 0.20004712045192719 }, right child: { prediction: 0, loss: 0.13242223858833313 }] }, Index(['PW_AGE <= 39.5', 'PREV_SB <= 0.0008262443006969988',\n       'PREV_SB <= 0.9977187514305115', 'PREV_MIS <= 5.817377768835286e-06',\n       'PREV_MIS <= 0.9999326467514038', 'GRAVIDITY <= 1.0036845803260803',\n       'GRAVIDITY <= 2.9981848001480103', 'GRAVIDITY <= 7.997529983520508',\n       'PARITY <= 1.0055058002471924', 'PARITY <= 2.006186008453369',\n       'SBP1 <= 114.00379943847656', 'SBP1 <= 128.00241088867188',\n       'DBP1 <= 65.01426696777344', 'UDIP_PROT1 <= 0.005180705804377794',\n       'UDIP_PROT1 <= 1.9963338971138', 'SBP2 <= 100.00275421142578',\n       'DBP2 <= 61.003665924072266', 'DBP2 <= 67.01312637329102',\n       'DBP2 <= 70.99264907836914', 'UDIP_PROT2 <= 0.0061516109853982925',\n       'UDIP_PROT2 <= 1.9994137287139893', 'SBP3 <= 111.02271270751953',\n       'SBP3 <= 112.00031280517578', 'SBP3 <= 115.98595428466797',\n       'SBP3 <= 118.99900436401367', 'DBP3 <= 70.01374435424805',\n       'DBP3 <= 72.99607849121094', 'DBP3 <= 73.99189376831055',\n       'UDIP_PROT3 <= 1.9967817068099976', 'SBP4 <= 100.13935852050781',\n       'SBP4 <= 111.00848007202148', 'SBP4 <= 112.00445938110352',\n       'SBP4 <= 114.0152816772461', 'DBP4 <= 65.01466369628906',\n       'DBP4 <= 67.0016098022461', 'DBP4 <= 72.00188064575195',\n       'DBP4 <= 73.99958419799805', 'MAT_WEIGHT <= 45.8147087097168',\n       'PREV_MULTIP <= 0.9951145648956299'],\n      dtype='object'), 2\n-> GOSDT (NumericBinarizer)\nTraining accuracy: 0.6675\nTree 1:\n<class 'gosdt._tree.Tree'>: { feature: 17953 [ left child: { prediction: 1, loss: 0.20004712045192719 }, right child: { prediction: 0, loss: 0.13242223858833313 }] }, Index(['PW_AGE <= 18.5', 'PW_AGE <= 19.5', 'PW_AGE <= 20.5', 'PW_AGE <= 21.5',\n       'PW_AGE <= 22.5', 'PW_AGE <= 23.5', 'PW_AGE <= 24.5', 'PW_AGE <= 25.5',\n       'PW_AGE <= 26.5', 'PW_AGE <= 27.5',\n       ...\n       'MAT_WEIGHT <= 106.69999999999999', 'MAT_WEIGHT <= 107.4',\n       'MAT_WEIGHT <= 108.30000000000001', 'MAT_WEIGHT <= 109.05000000000001',\n       'MAT_WEIGHT <= 110.5', 'MAT_WEIGHT <= 112.55',\n       'MAT_WEIGHT <= 113.44999999999999', 'MAT_WEIGHT <= 116.5',\n       'MAT_WEIGHT <= 122.2', 'LABOUR_24_1.0 <= 0.5'],\n      dtype='object', length=21086), 2\n-> GBDT Baseline\nTraining accuracy: 0.8148\nNumber of leaves: 120\n-> CART\nTraining accuracy: 1.0000\nNumber of leaves: 201\nCART Tree:\n|--- DBP4 <= 74.00\n|   |--- DBP4 <= 72.00\n|   |   |--- SBP3 <= 119.97\n|   |   |   |--- SBP3 <= 112.02\n|   |   |   |   |--- PREV_MIS <= 0.90\n|   |   |   |   |   |--- DBP1 <= 76.73\n|   |   |   |   |   |   |--- DBP3 <= 73.00\n|   |   |   |   |   |   |   |--- DBP3 <= 70.01\n|   |   |   |   |   |   |   |   |--- SBP4 <= 113.94\n|   |   |   |   |   |   |   |   |   |--- SBP4 <= 100.20\n|   |   |   |   |   |   |   |   |   |   |--- PW_AGE <= 20.50\n|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n|   |   |   |   |   |   |   |   |   |   |--- PW_AGE >  20.50\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |   |--- SBP4 >  100.20\n|   |   |   |   |   |   |   |   |   |   |--- MAT_WEIGHT <= 44.46\n|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n|   |   |   |   |   |   |   |   |   |   |--- MAT_WEIGHT >  44.46\n|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 13\n|   |   |   |   |   |   |   |   |--- SBP4 >  113.94\n|   |   |   |   |   |   |   |   |   |--- DBP3 <= 67.19\n|   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |   |--- DBP3 >  67.19\n|   |   |   |   |   |   |   |   |   |   |--- DBP3 <= 67.79\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |   |   |--- DBP3 >  67.79\n|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n|   |   |   |   |   |   |   |--- DBP3 >  70.01\n|   |   |   |   |   |   |   |   |--- SBP3 <= 106.02\n|   |   |   |   |   |   |   |   |   |--- UDIP_PROT2 <= 0.09\n|   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |   |--- UDIP_PROT2 >  0.09\n|   |   |   |   |   |   |   |   |   |   |--- MAT_WEIGHT <= 48.84\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |   |   |--- MAT_WEIGHT >  48.84\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |--- SBP3 >  106.02\n|   |   |   |   |   |   |   |   |   |--- SBP4 <= 119.88\n|   |   |   |   |   |   |   |   |   |   |--- SBP1 <= 121.51\n|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 5\n|   |   |   |   |   |   |   |   |   |   |--- SBP1 >  121.51\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |   |--- SBP4 >  119.88\n|   |   |   |   |   |   |   |   |   |   |--- SBP1 <= 116.29\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |   |   |--- SBP1 >  116.29\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |--- DBP3 >  73.00\n|   |   |   |   |   |   |   |--- SBP1 <= 98.35\n|   |   |   |   |   |   |   |   |--- SBP2 <= 101.00\n|   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |--- SBP2 >  101.00\n|   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |--- SBP1 >  98.35\n|   |   |   |   |   |   |   |   |--- SBP2 <= 97.00\n|   |   |   |   |   |   |   |   |   |--- DBP2 <= 66.50\n|   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |   |--- DBP2 >  66.50\n|   |   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |--- SBP2 >  97.00\n|   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |--- DBP1 >  76.73\n|   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |--- PREV_MIS >  0.90\n|   |   |   |   |   |--- class: 0.0\n|   |   |   |--- SBP3 >  112.02\n|   |   |   |   |--- DBP4 <= 66.01\n|   |   |   |   |   |--- MAT_WEIGHT <= 50.11\n|   |   |   |   |   |   |--- SBP3 <= 115.64\n|   |   |   |   |   |   |   |--- DBP3 <= 75.27\n|   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |--- DBP3 >  75.27\n|   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |--- SBP3 >  115.64\n|   |   |   |   |   |   |   |--- MAT_WEIGHT <= 48.63\n|   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |--- MAT_WEIGHT >  48.63\n|   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |--- MAT_WEIGHT >  50.11\n|   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |--- DBP4 >  66.01\n|   |   |   |   |   |--- DBP4 <= 72.00\n|   |   |   |   |   |   |--- GRAVIDITY <= 1.06\n|   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |--- GRAVIDITY >  1.06\n|   |   |   |   |   |   |   |--- PARITY <= 1.02\n|   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |--- PARITY >  1.02\n|   |   |   |   |   |   |   |   |--- UDIP_PROT1 <= 1.90\n|   |   |   |   |   |   |   |   |   |--- SBP4 <= 126.69\n|   |   |   |   |   |   |   |   |   |   |--- SBP2 <= 114.95\n|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 10\n|   |   |   |   |   |   |   |   |   |   |--- SBP2 >  114.95\n|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 6\n|   |   |   |   |   |   |   |   |   |--- SBP4 >  126.69\n|   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |--- UDIP_PROT1 >  1.90\n|   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |--- DBP4 >  72.00\n|   |   |   |   |   |   |--- UDIP_PROT1 <= 1.00\n|   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |--- UDIP_PROT1 >  1.00\n|   |   |   |   |   |   |   |--- DBP3 <= 74.00\n|   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |--- DBP3 >  74.00\n|   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |--- SBP3 >  119.97\n|   |   |   |--- UDIP_PROT2 <= 0.01\n|   |   |   |   |--- PREV_MIS <= 0.15\n|   |   |   |   |   |--- DBP1 <= 83.50\n|   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |--- DBP1 >  83.50\n|   |   |   |   |   |   |--- SBP2 <= 115.00\n|   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |--- SBP2 >  115.00\n|   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |--- PREV_MIS >  0.15\n|   |   |   |   |   |--- PREV_MIS <= 0.98\n|   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |--- PREV_MIS >  0.98\n|   |   |   |   |   |   |--- UDIP_PROT1 <= 1.00\n|   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |--- UDIP_PROT1 >  1.00\n|   |   |   |   |   |   |   |--- DBP4 <= 64.50\n|   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |--- DBP4 >  64.50\n|   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |--- UDIP_PROT2 >  0.01\n|   |   |   |   |--- UDIP_PROT2 <= 2.00\n|   |   |   |   |   |--- class: 1.0\n|   |   |   |   |--- UDIP_PROT2 >  2.00\n|   |   |   |   |   |--- SBP1 <= 134.50\n|   |   |   |   |   |   |--- SBP4 <= 126.00\n|   |   |   |   |   |   |   |--- PREV_MIS <= 1.50\n|   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |--- PREV_MIS >  1.50\n|   |   |   |   |   |   |   |   |--- MAT_WEIGHT <= 56.15\n|   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |--- MAT_WEIGHT >  56.15\n|   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |--- SBP4 >  126.00\n|   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |--- SBP1 >  134.50\n|   |   |   |   |   |   |--- DBP3 <= 85.86\n|   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |--- DBP3 >  85.86\n|   |   |   |   |   |   |   |--- class: 0.0\n|   |--- DBP4 >  72.00\n|   |   |--- SBP4 <= 119.98\n|   |   |   |--- SBP4 <= 111.10\n|   |   |   |   |--- UDIP_PROT2 <= 0.40\n|   |   |   |   |   |--- class: 0.0\n|   |   |   |   |--- UDIP_PROT2 >  0.40\n|   |   |   |   |   |--- UDIP_PROT2 <= 1.89\n|   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |--- UDIP_PROT2 >  1.89\n|   |   |   |   |   |   |--- class: 0.0\n|   |   |   |--- SBP4 >  111.10\n|   |   |   |   |--- DBP2 <= 62.23\n|   |   |   |   |   |--- class: 0.0\n|   |   |   |   |--- DBP2 >  62.23\n|   |   |   |   |   |--- UDIP_PROT3 <= 1.20\n|   |   |   |   |   |   |--- SBP3 <= 117.86\n|   |   |   |   |   |   |   |--- MAT_WEIGHT <= 82.61\n|   |   |   |   |   |   |   |   |--- DBP2 <= 64.02\n|   |   |   |   |   |   |   |   |   |--- GRAVIDITY <= 5.50\n|   |   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |   |--- GRAVIDITY >  5.50\n|   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |--- DBP2 >  64.02\n|   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |--- MAT_WEIGHT >  82.61\n|   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |--- SBP3 >  117.86\n|   |   |   |   |   |   |   |--- SBP1 <= 117.68\n|   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |--- SBP1 >  117.68\n|   |   |   |   |   |   |   |   |--- MAT_WEIGHT <= 97.40\n|   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |--- MAT_WEIGHT >  97.40\n|   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |--- UDIP_PROT3 >  1.20\n|   |   |   |   |   |   |--- class: 0.0\n|   |   |--- SBP4 >  119.98\n|   |   |   |--- DBP4 <= 73.04\n|   |   |   |   |--- class: 0.0\n|   |   |   |--- DBP4 >  73.04\n|   |   |   |   |--- class: 1.0\n|--- DBP4 >  74.00\n|   |--- DBP4 <= 74.01\n|   |   |--- SBP4 <= 107.00\n|   |   |   |--- DBP3 <= 68.50\n|   |   |   |   |--- class: 1.0\n|   |   |   |--- DBP3 >  68.50\n|   |   |   |   |--- class: 0.0\n|   |   |--- SBP4 >  107.00\n|   |   |   |--- PARITY <= 0.50\n|   |   |   |   |--- SBP4 <= 117.00\n|   |   |   |   |   |--- class: 1.0\n|   |   |   |   |--- SBP4 >  117.00\n|   |   |   |   |   |--- class: 0.0\n|   |   |   |--- PARITY >  0.50\n|   |   |   |   |--- DBP1 <= 61.50\n|   |   |   |   |   |--- DBP2 <= 73.50\n|   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |--- DBP2 >  73.50\n|   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |--- DBP1 >  61.50\n|   |   |   |   |   |--- DBP3 <= 64.50\n|   |   |   |   |   |   |--- PREV_MIS <= 0.50\n|   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |--- PREV_MIS >  0.50\n|   |   |   |   |   |   |   |--- DBP1 <= 69.00\n|   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |--- DBP1 >  69.00\n|   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |--- DBP3 >  64.50\n|   |   |   |   |   |   |--- class: 0.0\n|   |--- DBP4 >  74.01\n|   |   |--- DBP4 <= 74.99\n|   |   |   |--- class: 1.0\n|   |   |--- DBP4 >  74.99\n|   |   |   |--- SBP4 <= 114.02\n|   |   |   |   |--- SBP4 <= 113.33\n|   |   |   |   |   |--- class: 0.0\n|   |   |   |   |--- SBP4 >  113.33\n|   |   |   |   |   |--- SBP4 <= 113.97\n|   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |--- SBP4 >  113.97\n|   |   |   |   |   |   |--- class: 0.0\n|   |   |   |--- SBP4 >  114.02\n|   |   |   |   |--- UDIP_PROT3 <= 2.00\n|   |   |   |   |   |--- UDIP_PROT3 <= 0.06\n|   |   |   |   |   |   |--- GRAVIDITY <= 3.01\n|   |   |   |   |   |   |   |--- PREV_SB <= 0.04\n|   |   |   |   |   |   |   |   |--- MAT_WEIGHT <= 64.56\n|   |   |   |   |   |   |   |   |   |--- SBP2 <= 100.50\n|   |   |   |   |   |   |   |   |   |   |--- DBP3 <= 63.50\n|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n|   |   |   |   |   |   |   |   |   |   |--- DBP3 >  63.50\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |   |--- SBP2 >  100.50\n|   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |--- MAT_WEIGHT >  64.56\n|   |   |   |   |   |   |   |   |   |--- DBP3 <= 73.50\n|   |   |   |   |   |   |   |   |   |   |--- MAT_WEIGHT <= 80.92\n|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 4\n|   |   |   |   |   |   |   |   |   |   |--- MAT_WEIGHT >  80.92\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |   |--- DBP3 >  73.50\n|   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |--- PREV_SB >  0.04\n|   |   |   |   |   |   |   |   |--- PREV_SB <= 0.98\n|   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |--- PREV_SB >  0.98\n|   |   |   |   |   |   |   |   |   |--- SBP2 <= 112.00\n|   |   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |   |--- SBP2 >  112.00\n|   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |--- GRAVIDITY >  3.01\n|   |   |   |   |   |   |   |--- DBP2 <= 73.93\n|   |   |   |   |   |   |   |   |--- GRAVIDITY <= 8.00\n|   |   |   |   |   |   |   |   |   |--- GRAVIDITY <= 6.02\n|   |   |   |   |   |   |   |   |   |   |--- GRAVIDITY <= 3.97\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |   |   |--- GRAVIDITY >  3.97\n|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 6\n|   |   |   |   |   |   |   |   |   |--- GRAVIDITY >  6.02\n|   |   |   |   |   |   |   |   |   |   |--- PREV_SB <= 0.58\n|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 13\n|   |   |   |   |   |   |   |   |   |   |--- PREV_SB >  0.58\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |--- GRAVIDITY >  8.00\n|   |   |   |   |   |   |   |   |   |--- MAT_WEIGHT <= 101.90\n|   |   |   |   |   |   |   |   |   |   |--- DBP2 <= 71.23\n|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 5\n|   |   |   |   |   |   |   |   |   |   |--- DBP2 >  71.23\n|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 4\n|   |   |   |   |   |   |   |   |   |--- MAT_WEIGHT >  101.90\n|   |   |   |   |   |   |   |   |   |   |--- DBP4 <= 85.20\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |   |   |--- DBP4 >  85.20\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |--- DBP2 >  73.93\n|   |   |   |   |   |   |   |   |--- GRAVIDITY <= 3.98\n|   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |--- GRAVIDITY >  3.98\n|   |   |   |   |   |   |   |   |   |--- DBP1 <= 61.87\n|   |   |   |   |   |   |   |   |   |   |--- DBP3 <= 70.39\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |   |   |   |--- DBP3 >  70.39\n|   |   |   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |   |--- DBP1 >  61.87\n|   |   |   |   |   |   |   |   |   |   |--- PARITY <= 11.09\n|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 8\n|   |   |   |   |   |   |   |   |   |   |--- PARITY >  11.09\n|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n|   |   |   |   |   |--- UDIP_PROT3 >  0.06\n|   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |--- UDIP_PROT3 >  2.00\n|   |   |   |   |   |--- SBP4 <= 118.50\n|   |   |   |   |   |   |--- SBP3 <= 105.50\n|   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |--- SBP3 >  105.50\n|   |   |   |   |   |   |   |--- DBP2 <= 80.50\n|   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |   |   |--- DBP2 >  80.50\n|   |   |   |   |   |   |   |   |--- SBP2 <= 162.50\n|   |   |   |   |   |   |   |   |   |--- class: 1.0\n|   |   |   |   |   |   |   |   |--- SBP2 >  162.50\n|   |   |   |   |   |   |   |   |   |--- class: 0.0\n|   |   |   |   |   |--- SBP4 >  118.50\n|   |   |   |   |   |   |--- class: 0.0\n\n\n=== Average Results Over 5 Folds ===\n\nGOSDT_Guessed:\n  Average Train Accuracy: 0.6584\n  Average Test Accuracy:  0.6001\n  Average Train Time:     0.0235s\n  Average Test Time:      0.0034s\n\nGOSDT_Numerical:\n  Average Train Accuracy: 0.6584\n  Average Test Accuracy:  0.6001\n  Average Train Time:     4.5951s\n  Average Test Time:      0.1937s\n\nGBDT_Baseline:\n  Average Train Accuracy: 0.8125\n  Average Test Accuracy:  0.8092\n  Average Train Time:     0.3951s\n  Average Test Time:      0.0034s\n  Average Number of Leaves: 120\n\nCART:\n  Average Train Accuracy: 1.0000\n  Average Test Accuracy:  0.9067\n  Average Train Time:     0.0647s\n  Average Test Time:      0.0020s\n  Average Number of Leaves: 204\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x400 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport time\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier, export_text\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom imblearn.over_sampling import SMOTE\nfrom gosdt import GOSDTClassifier, ThresholdGuessBinarizer, NumericBinarizer\n\n# Load Antepartum Hemorrhage data\n# df = pd.read_csv(\"/content/aph.csv\")  # Uncomment and update the path if needed\n# X, y = df.iloc[:, :-1], df.iloc[:, -1]\n\n# Set random seed and Stratified KFold\nSEED = 42\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n\n# Initialize metrics and times dictionaries\nmetrics = {\n    \"GOSDT_Guessed\": {\"train_acc\": [], \"test_acc\": [], \"train_time\": [], \"test_time\": []},\n    \"GOSDT_Numerical\": {\"train_acc\": [], \"test_acc\": [], \"train_time\": [], \"test_time\": []},\n    \"GBDT_Baseline\": {\"train_acc\": [], \"test_acc\": [], \"train_time\": [], \"test_time\": [], \"n_leaves\": []},\n    \"CART\": {\"train_acc\": [], \"test_acc\": [], \"train_time\": [], \"test_time\": [], \"n_leaves\": []},\n}\n\n# Helper function to get feature names safely\ndef get_feature_names(X):\n    if hasattr(X, 'columns'):\n        # Convert column names to strings to avoid non-string type issues\n        return [str(col) for col in X.columns]\n    else:\n        # Fallback for NumPy arrays or other types without columns\n        return [f\"feature_{i}\" for i in range(X.shape[1])]\n\nfor fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n    print(f\"\\n=== Fold {fold + 1} ===\")\n\n    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n\n    # SMOTE on training data only\n    smote = SMOTE(random_state=SEED, sampling_strategy=1)\n    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n\n    # Get feature names for tree visualization\n    feature_names = get_feature_names(X)\n\n    # -------- GOSDT with ThresholdGuessBinarizer --------\n    print(\"-> GOSDT (ThresholdGuessBinarizer + y_ref)\")\n    tgb = ThresholdGuessBinarizer(n_estimators=200, max_depth=3, random_state=SEED)\n    tgb.set_output(transform=\"pandas\")\n    X_train_guess = tgb.fit_transform(X_train_res.copy(), y_train_res.copy())\n    X_test_guess = tgb.transform(X_test.copy())\n\n    gbdt_ref = GradientBoostingClassifier(n_estimators=60, max_depth=3, random_state=SEED)\n    gbdt_ref.fit(X_train_guess, y_train_res)\n    warm_labels = gbdt_ref.predict(X_train_guess)\n\n    clf_guess = GOSDTClassifier(regularization=0.001, depth_budget=1, time_limit=1800)\n\n    start_train = time.time()\n    clf_guess.fit(X_train_guess, y_train_res, y_ref=warm_labels)\n    end_train = time.time()\n    metrics[\"GOSDT_Guessed\"][\"train_time\"].append(end_train - start_train)\n\n    start_test = time.time()\n    y_pred_test_g = clf_guess.predict(X_test_guess)\n    end_test = time.time()\n    metrics[\"GOSDT_Guessed\"][\"test_time\"].append(end_test - start_test)\n\n    y_pred_train_g = clf_guess.predict(X_train_guess)\n\n    metrics[\"GOSDT_Guessed\"][\"train_acc\"].append(accuracy_score(y_train_res, y_pred_train_g))\n    metrics[\"GOSDT_Guessed\"][\"test_acc\"].append(accuracy_score(y_test, y_pred_test_g))\n\n    print(f\"Training accuracy: {clf_guess.score(X_train_guess, y_train_res):.4f}\")\n    for i, tree in enumerate(clf_guess.trees_):\n        print(f\"Tree {i + 1}:\")\n        print(tree)\n\n    # -------- GOSDT with NumericBinarizer --------\n    print(\"-> GOSDT (NumericBinarizer)\")\n    nb = NumericBinarizer()\n    nb.set_output(transform=\"pandas\")\n    X_train_num = nb.fit_transform(X_train_res.copy(), y_train_res.copy())\n    X_test_num = nb.transform(X_test.copy())\n\n    clf_num = GOSDTClassifier(regularization=0.001, depth_budget=1, time_limit=1800)\n\n    start_train = time.time()\n    clf_num.fit(X_train_num, y_train_res)\n    end_train = time.time()\n    metrics[\"GOSDT_Numerical\"][\"train_time\"].append(end_train - start_train)\n\n    start_test = time.time()\n    y_pred_test_n = clf_num.predict(X_test_num)\n    end_test = time.time()\n    metrics[\"GOSDT_Numerical\"][\"test_time\"].append(end_test - start_test)\n\n    y_pred_train_n = clf_num.predict(X_train_num)\n\n    metrics[\"GOSDT_Numerical\"][\"train_acc\"].append(accuracy_score(y_train_res, y_pred_train_n))\n    metrics[\"GOSDT_Numerical\"][\"test_acc\"].append(accuracy_score(y_test, y_pred_test_n))\n\n    print(f\"Training accuracy: {clf_num.score(X_train_num, y_train_res):.4f}\")\n    for i, tree in enumerate(clf_num.trees_):\n        print(f\"Tree {i + 1}:\")\n        print(tree)\n\n    # -------- GBDT Baseline --------\n    print(\"-> GBDT Baseline\")\n    gbdt = GradientBoostingClassifier(n_estimators=60, max_depth=3, random_state=SEED)\n\n    start_train = time.time()\n    gbdt.fit(X_train_res, y_train_res)\n    end_train = time.time()\n    metrics[\"GBDT_Baseline\"][\"train_time\"].append(end_train - start_train)\n\n    start_test = time.time()\n    y_pred_test_b = gbdt.predict(X_test)\n    end_test = time.time()\n    metrics[\"GBDT_Baseline\"][\"test_time\"].append(end_test - start_test)\n\n    y_pred_train_b = gbdt.predict(X_train_res)\n\n    # Calculate total number of leaves across all GBDT trees\n    n_leaves = sum(tree.tree_.n_leaves for est in gbdt.estimators_ for tree in est)\n    metrics[\"GBDT_Baseline\"][\"n_leaves\"].append(n_leaves)\n\n    metrics[\"GBDT_Baseline\"][\"train_acc\"].append(accuracy_score(y_train_res, y_pred_train_b))\n    metrics[\"GBDT_Baseline\"][\"test_acc\"].append(accuracy_score(y_test, y_pred_test_b))\n\n    print(f\"Training accuracy: {gbdt.score(X_train_res, y_train_res):.4f}\")\n    print(f\"Number of leaves: {n_leaves}\")\n    # Print first 5 GBDT trees for inspection\n    for i, tree in enumerate(sum(gbdt.estimators_, [])):\n        if i < 5:\n            print(f\"GBDT Tree {i + 1}:\")\n            tree_str = export_text(tree, feature_names=feature_names)\n            print(tree_str)\n\n    # -------- CART --------\n    print(\"-> CART\")\n    cart = DecisionTreeClassifier(max_depth=3, random_state=SEED)  # Aligned with GOSDT depth_budget\n\n    start_train = time.time()\n    cart.fit(X_train_res, y_train_res)\n    end_train = time.time()\n    metrics[\"CART\"][\"train_time\"].append(end_train - start_train)\n\n    start_test = time.time()\n    y_pred_test_c = cart.predict(X_test)\n    end_test = time.time()\n    metrics[\"CART\"][\"test_time\"].append(end_test - start_test)\n\n    y_pred_train_c = cart.predict(X_train_res)\n\n    # Calculate number of leaves for CART\n    n_leaves = cart.tree_.n_leaves  # Number of terminal nodes in the tree\n    metrics[\"CART\"][\"n_leaves\"].append(n_leaves)\n\n    metrics[\"CART\"][\"train_acc\"].append(accuracy_score(y_train_res, y_pred_train_c))\n    metrics[\"CART\"][\"test_acc\"].append(accuracy_score(y_test, y_pred_test_c))\n\n    print(f\"Training accuracy: {cart.score(X_train_res, y_train_res):.4f}\")\n    print(f\"Number of leaves: {n_leaves} (verified as terminal nodes)\")\n    print(\"CART Tree:\")\n    # Use export_text with safe feature names\n    try:\n        tree_str = export_text(cart, feature_names=feature_names)\n        print(tree_str)\n    except Exception as e:\n        print(f\"Error in export_text: {e}\")\n        print(\"Falling back to default feature names\")\n        tree_str = export_text(cart)\n        print(tree_str)\n    # Verify leaf count manually\n    tree_nodes = cart.tree_.node_count\n    children_left = cart.tree_.children_left\n    children_right = cart.tree_.children_right\n    manual_leaf_count = sum(1 for i in range(tree_nodes) if children_left[i] == children_right[i] == -1)\n    print(f\"Manually counted leaves: {manual_leaf_count} (should match n_leaves)\")\n    print(f\"Feature names used: {feature_names}\")\n\n# ------------------ Results ------------------\nprint(\"\\n=== Average Results Over 5 Folds ===\")\nfor model in metrics:\n    print(f\"\\n{model}:\")\n    print(f\"  Average Train Accuracy: {np.mean(metrics[model]['train_acc']):.4f}\")\n    print(f\"  Average Test Accuracy:  {np.mean(metrics[model]['test_acc']):.4f}\")\n    print(f\"  Average Train Time:     {np.mean(metrics[model]['train_time']):.4f}s\")\n    print(f\"  Average Test Time:      {np.mean(metrics[model]['test_time']):.4f}s\")\n    if \"n_leaves\" in metrics[model]:\n        print(f\"  Average Number of Leaves: {np.mean(metrics[model]['n_leaves']):.0f}\")\n\n# ------------------ Plot Accuracy and Training Time ------------------\nlabels = list(metrics.keys())\ntest_accuracies = [np.mean(metrics[m][\"test_acc\"]) for m in labels]\ntrain_times = [np.mean(metrics[m][\"train_time\"]) for m in labels]\n\nplt.figure(figsize=(12, 4))\n# Plot: Accuracy\nplt.subplot(1, 2, 1)\nbars = plt.bar(labels, test_accuracies, color=[\"cornflowerblue\", \"lightcoral\", \"lightgreen\", \"lightgoldenrodyellow\"])\nplt.ylabel(\"Average Test Accuracy\")\nplt.title(\"APH Dataset: GOSDT vs GBDT vs CART (SMOTE + Stratified KFold)\")\nfor bar, acc in zip(bars, test_accuracies):\n    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f\"{acc:.4f}\", ha='center', va='bottom')\nplt.xticks(rotation=15)\n\n# Plot: Training Time (log scale)\nplt.subplot(1, 2, 2)\nbars = plt.bar(labels, train_times, color=[\"cornflowerblue\", \"lightcoral\", \"lightgreen\", \"lightgoldenrodyellow\"])\nplt.yscale(\"log\")\nplt.ylabel(\"Train Time (s, log scale)\")\nplt.title(\"Average Training Time\")\nfor bar, time_val in zip(bars, train_times):\n    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f\"{time_val:.2f}\", ha='center', va='bottom')\nplt.xticks(rotation=15)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport time\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier, export_text\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom imblearn.over_sampling import SMOTE\nfrom gosdt import GOSDTClassifier, ThresholdGuessBinarizer, NumericBinarizer\n\n# Load Antepartum Hemorrhage data\n# df = pd.read_csv(\"/content/aph.csv\")  # Uncomment and update the path if needed\n# X, y = df.iloc[:, :-1], df.iloc[:, -1]\n\n# Set random seed and Stratified KFold\nSEED = 42\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n\n# Initialize metrics and times dictionaries\nmetrics = {\n    \"GOSDT_Guessed\": {\"train_acc\": [], \"test_acc\": [], \"train_time\": [], \"test_time\": []},\n    \"GOSDT_Numerical\": {\"train_acc\": [], \"test_acc\": [], \"train_time\": [], \"test_time\": []},\n    \"GBDT_Baseline\": {\"train_acc\": [], \"test_acc\": [], \"train_time\": [], \"test_time\": [], \"n_leaves\": []},\n    \"CART\": {\"train_acc\": [], \"test_acc\": [], \"train_time\": [], \"test_time\": [], \"n_leaves\": []},\n}\n\nfor fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n    print(f\"\\n=== Fold {fold + 1} ===\")\n\n    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n\n    # SMOTE on training data only\n    smote = SMOTE(random_state=SEED, sampling_strategy=1)\n    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n\n    # -------- GOSDT with ThresholdGuessBinarizer --------\n    print(\"-> GOSDT (ThresholdGuessBinarizer + y_ref)\")\n    tgb = ThresholdGuessBinarizer(n_estimators=200, max_depth=1, random_state=SEED)\n    tgb.set_output(transform=\"pandas\")\n    X_train_guess = tgb.fit_transform(X_train_res.copy(), y_train_res.copy())\n    X_test_guess = tgb.transform(X_test.copy())\n\n    gbdt_ref = GradientBoostingClassifier(n_estimators=60, max_depth=3, random_state=SEED)\n    gbdt_ref.fit(X_train_guess, y_train_res)\n    warm_labels = gbdt_ref.predict(X_train_guess)\n\n    clf_guess = GOSDTClassifier(regularization=0.001, depth_budget=3, time_limit=1800)\n\n    start_train = time.time()\n    clf_guess.fit(X_train_guess, y_train_res, y_ref=warm_labels)\n    end_train = time.time()\n    metrics[\"GOSDT_Guessed\"][\"train_time\"].append(end_train - start_train)\n\n    start_test = time.time()\n    y_pred_test_g = clf_guess.predict(X_test_guess)\n    end_test = time.time()\n    metrics[\"GOSDT_Guessed\"][\"test_time\"].append(end_test - start_test)\n\n    y_pred_train_g = clf_guess.predict(X_train_guess)\n\n    metrics[\"GOSDT_Guessed\"][\"train_acc\"].append(accuracy_score(y_train_res, y_pred_train_g))\n    metrics[\"GOSDT_Guessed\"][\"test_acc\"].append(accuracy_score(y_test, y_pred_test_g))\n\n    print(f\"Training accuracy: {clf_guess.score(X_train_guess, y_train_res):.4f}\")\n    for i, tree in enumerate(clf_guess.trees_):\n        print(f\"Tree {i + 1}:\")\n        print(tree)\n\n    # -------- GOSDT with NumericBinarizer --------\n    print(\"-> GOSDT (NumericBinarizer)\")\n    nb = NumericBinarizer()\n    nb.set_output(transform=\"pandas\")\n    X_train_num = nb.fit_transform(X_train_res.copy(), y_train_res.copy())\n    X_test_num = nb.transform(X_test.copy())\n\n    clf_num = GOSDTClassifier(regularization=0.001, depth_budget=3, time_limit=1800)\n\n    start_train = time.time()\n    clf_num.fit(X_train_num, y_train_res)\n    end_train = time.time()\n    metrics[\"GOSDT_Numerical\"][\"train_time\"].append(end_train - start_train)\n\n    start_test = time.time()\n    y_pred_test_n = clf_num.predict(X_test_num)\n    end_test = time.time()\n    metrics[\"GOSDT_Numerical\"][\"test_time\"].append(end_test - start_test)\n\n    y_pred_train_n = clf_num.predict(X_train_num)\n\n    metrics[\"GOSDT_Numerical\"][\"train_acc\"].append(accuracy_score(y_train_res, y_pred_train_n))\n    metrics[\"GOSDT_Numerical\"][\"test_acc\"].append(accuracy_score(y_test, y_pred_test_n))\n\n    print(f\"Training accuracy: {clf_num.score(X_train_num, y_train_res):.4f}\")\n    for i, tree in enumerate(clf_num.trees_):\n        print(f\"Tree {i + 1}:\")\n        print(tree)\n\n    # -------- GBDT Baseline --------\n    print(\"-> GBDT Baseline\")\n    gbdt = GradientBoostingClassifier(n_estimators=60, max_depth=3, random_state=SEED)\n\n    start_train = time.time()\n    gbdt.fit(X_train_res, y_train_res)\n    end_train = time.time()\n    metrics[\"GBDT_Baseline\"][\"train_time\"].append(end_train - start_train)\n\n    start_test = time.time()\n    y_pred_test_b = gbdt.predict(X_test)\n    end_test = time.time()\n    metrics[\"GBDT_Baseline\"][\"test_time\"].append(end_test - start_test)\n\n    y_pred_train_b = gbdt.predict(X_train_res)\n\n    # Calculate total number of leaves across all GBDT trees\n    n_leaves = sum(tree.tree_.n_leaves for est in gbdt.estimators_ for tree in est)\n    metrics[\"GBDT_Baseline\"][\"n_leaves\"].append(n_leaves)\n\n    metrics[\"GBDT_Baseline\"][\"train_acc\"].append(accuracy_score(y_train_res, y_pred_train_b))\n    metrics[\"GBDT_Baseline\"][\"test_acc\"].append(accuracy_score(y_test, y_pred_test_b))\n\n    print(f\"Training accuracy: {gbdt.score(X_train_res, y_train_res):.4f}\")\n    print(f\"Number of leaves: {n_leaves}\")\n    # Print first 5 GBDT trees for inspection\n    feature_names = X.columns\n    for i, tree in enumerate(sum(gbdt.estimators_, [])):\n        if i < 5:\n            print(f\"GBDT Tree {i + 1}:\")\n            tree_str = export_text(tree, feature_names=feature_names)\n            print(tree_str)\n\n    # -------- CART --------\n    print(\"-> CART\")\n    cart = DecisionTreeClassifier(max_depth=3, random_state=SEED)  # Aligned with GOSDT depth_budget\n\n    start_train = time.time()\n    cart.fit(X_train_res, y_train_res)\n    end_train = time.time()\n    metrics[\"CART\"][\"train_time\"].append(end_train - start_train)\n\n    start_test = time.time()\n    y_pred_test_c = cart.predict(X_test)\n    end_test = time.time()\n    metrics[\"CART\"][\"test_time\"].append(end_test - start_test)\n\n    y_pred_train_c = cart.predict(X_train_res)\n\n    # Calculate number of leaves for CART (leaf nodes are terminal nodes in the tree)\n    n_leaves = cart.tree_.n_leaves  # Direct access to the number of leaf nodes\n    metrics[\"CART\"][\"n_leaves\"].append(n_leaves)\n\n    metrics[\"CART\"][\"train_acc\"].append(accuracy_score(y_train_res, y_pred_train_c))\n    metrics[\"CART\"][\"test_acc\"].append(accuracy_score(y_test, y_pred_test_c))\n\n    print(f\"Training accuracy: {cart.score(X_train_res, y_train_res):.4f}\")\n    print(f\"Number of leaves: {n_leaves} (verified as terminal nodes in the decision tree)\")\n    print(\"CART Tree:\")\n    tree_str = export_text(cart, feature_names=X.columns)\n    print(tree_str)\n    # Additional debugging: Count leaves manually from tree structure\n    tree_nodes = cart.tree_.node_count\n    children_left = cart.tree_.children_left\n    children_right = cart.tree_.children_right\n    manual_leaf_count = sum(1 for i in range(tree_nodes) if children_left[i] == children_right[i] == -1)\n    print(f\"Manually counted leaves: {manual_leaf_count} (should match n_leaves)\")\n\n# ------------------ Results ------------------\nprint(\"\\n=== Average Results Over 5 Folds ===\")\nfor model in metrics:\n    print(f\"\\n{model}:\")\n    print(f\"  Average Train Accuracy: {np.mean(metrics[model]['train_acc']):.4f}\")\n    print(f\"  Average Test Accuracy:  {np.mean(metrics[model]['test_acc']):.4f}\")\n    print(f\"  Average Train Time:     {np.mean(metrics[model]['train_time']):.4f}s\")\n    print(f\"  Average Test Time:      {np.mean(metrics[model]['test_time']):.4f}s\")\n    if \"n_leaves\" in metrics[model]:\n        print(f\"  Average Number of Leaves: {np.mean(metrics[model]['n_leaves']):.0f}\")\n\n# ------------------ Plot Accuracy and Training Time ------------------\nlabels = list(metrics.keys())\ntest_accuracies = [np.mean(metrics[m][\"test_acc\"]) for m in labels]\ntrain_times = [np.mean(metrics[m][\"train_time\"]) for m in labels]\n\nplt.figure(figsize=(12, 4))\n# Plot: Accuracy\nplt.subplot(1, 2, 1)\nbars = plt.bar(labels, test_accuracies, color=[\"cornflowerblue\", \"lightcoral\", \"lightgreen\", \"lightgoldenrodyellow\"])\nplt.ylabel(\"Average Test Accuracy\")\nplt.title(\"APH Dataset: GOSDT vs GBDT vs CART (SMOTE + Stratified KFold)\")\nfor bar, acc in zip(bars, test_accuracies):\n    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f\"{acc:.4f}\", ha='center', va='bottom')\nplt.xticks(rotation=15)\n\n# Plot: Training Time (log scale)\nplt.subplot(1, 2, 2)\nbars = plt.bar(labels, train_times, color=[\"cornflowerblue\", \"lightcoral\", \"lightgreen\", \"lightgoldenrodyellow\"])\nplt.yscale(\"log\")\nplt.ylabel(\"Train Time (s, log scale)\")\nplt.title(\"Average Training Time\")\nfor bar, time_val in zip(bars, train_times):\n    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height(), f\"{time_val:.2f}\", ha='center', va='bottom')\nplt.xticks(rotation=15)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# APH final","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport time\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom imblearn.over_sampling import SMOTE\nfrom gosdt import GOSDTClassifier, ThresholdGuessBinarizer, NumericBinarizer\n\n# Load Antepartum Hemorrhage data\n# df = pd.read_csv(\"/content/aph.csv\")  # Uncomment and update the path if needed\n# X, y = df.iloc[:, :-1], df.iloc[:, -1]\nGBDT_N_EST = 200\nGBDT_MAX_DEPTH = 3\n# Set random seed and Stratified KFold\nSEED = 42\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n\nmetrics = {\n    \"GOSDT_Guessed\": {\"train_acc\": [], \"test_acc\": []},\n    \"GOSDT_Numerical\": {\"train_acc\": [], \"test_acc\": []},\n    \"GBDT_Baseline\": {\"train_acc\": [], \"test_acc\": []},\n}\n\ntimes = {\n    \"GOSDT_Guessed\": {\"train_time\": [], \"test_time\": []},\n    \"GOSDT_Numerical\": {\"train_time\": [], \"test_time\": []},\n    \"GBDT_Baseline\": {\"train_time\": [], \"test_time\": []},\n}\n\nfor fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n    print(f\"\\n=== Fold {fold + 1} ===\")\n\n    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n\n    # SMOTE on training data only\n    smote = SMOTE(random_state=SEED, sampling_strategy=1)\n    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n\n    # -------- GOSDT with ThresholdGuessBinarizer --------\n    print(\"-> GOSDT (ThresholdGuessBinarizer + y_ref)\")\n    tgb = ThresholdGuessBinarizer(n_estimators=GBDT_N_EST, max_depth=GBDT_MAX_DEPTH, random_state=SEED)\n    tgb.set_output(transform=\"pandas\")\n    X_train_guess = tgb.fit_transform(X_train_res.copy(), y_train_res.copy())\n    X_test_guess = tgb.transform(X_test.copy())\n\n    gbdt_ref = GradientBoostingClassifier(n_estimators=GBDT_N_EST, max_depth=GBDT_MAX_DEPTH, random_state=SEED)\n    gbdt_ref.fit(X_train_guess, y_train_res)\n    warm_labels = gbdt_ref.predict(X_train_guess)\n\n    clf_guess = GOSDTClassifier(regularization=0.001, depth_budget=2, time_limit=1800)\n\n    start_train = time.time()\n    clf_guess.fit(X_train_guess, y_train_res, y_ref=warm_labels)\n    end_train = time.time()\n    times[\"GOSDT_Guessed\"][\"train_time\"].append(end_train - start_train)\n\n    start_test = time.time()\n    y_pred_test_g = clf_guess.predict(X_test_guess)\n    end_test = time.time()\n    times[\"GOSDT_Guessed\"][\"test_time\"].append(end_test - start_test)\n\n    y_pred_train_g = clf_guess.predict(X_train_guess)\n\n    metrics[\"GOSDT_Guessed\"][\"train_acc\"].append(accuracy_score(y_train_res, y_pred_train_g))\n    metrics[\"GOSDT_Guessed\"][\"test_acc\"].append(accuracy_score(y_test, y_pred_test_g))\n\n    # -------- GOSDT with NumericBinarizer --------\n    print(\"-> GOSDT (NumericBinarizer)\")\n    nb = NumericBinarizer()\n    nb.set_output(transform=\"pandas\")\n    X_train_num = nb.fit_transform(X_train_res.copy(), y_train_res.copy())\n    X_test_num = nb.transform(X_test.copy())\n\n    clf_num = GOSDTClassifier(regularization=0.001, depth_budget=2, time_limit=1800)\n\n    start_train = time.time()\n    clf_num.fit(X_train_num, y_train_res)\n    end_train = time.time()\n    times[\"GOSDT_Numerical\"][\"train_time\"].append(end_train - start_train)\n\n    start_test = time.time()\n    y_pred_test_n = clf_num.predict(X_test_num)\n    end_test = time.time()\n    times[\"GOSDT_Numerical\"][\"test_time\"].append(end_test - start_test)\n\n    y_pred_train_n = clf_num.predict(X_train_num)\n\n    metrics[\"GOSDT_Numerical\"][\"train_acc\"].append(accuracy_score(y_train_res, y_pred_train_n))\n    metrics[\"GOSDT_Numerical\"][\"test_acc\"].append(accuracy_score(y_test, y_pred_test_n))\n\n    # -------- GBDT Baseline --------\n    print(\"-> GBDT Baseline\")\n    gbdt = GradientBoostingClassifier(n_estimators=GBDT_N_EST, max_depth=GBDT_MAX_DEPTH, random_state=SEED)\n\n    start_train = time.time()\n    gbdt.fit(X_train_res, y_train_res)\n    end_train = time.time()\n    times[\"GBDT_Baseline\"][\"train_time\"].append(end_train - start_train)\n\n    start_test = time.time()\n    y_pred_test_b = gbdt.predict(X_test)\n    end_test = time.time()\n    times[\"GBDT_Baseline\"][\"test_time\"].append(end_test - start_test)\n\n    y_pred_train_b = gbdt.predict(X_train_res)\n\n    metrics[\"GBDT_Baseline\"][\"train_acc\"].append(accuracy_score(y_train_res, y_pred_train_b))\n    metrics[\"GBDT_Baseline\"][\"test_acc\"].append(accuracy_score(y_test, y_pred_test_b))\n\n# ------------------ Accuracy Results ------------------\nprint(\"\\n=== Median Accuracy Results Over Folds ===\")\nfor model in metrics:\n    print(f\"\\n{model}:\")\n    print(f\"  Median Train Accuracy: {np.median(metrics[model]['train_acc']):.4f}\")\n    print(f\"  Median Test Accuracy:  {np.median(metrics[model]['test_acc']):.4f}\")\n\n# ------------------ Timing Results ------------------\nprint(\"\\n=== Median Training & Testing Time (seconds) ===\")\nfor model in times:\n    print(f\"\\n{model}:\")\n    print(f\"  Median Train Time: {np.median(times[model]['train_time']):.2f} sec\")\n    print(f\"  Median Test Time:  {np.median(times[model]['test_time']):.4f} sec\")\n\n# ------------------ Optional: Plot Accuracy ------------------\nlabels = list(metrics.keys())\nmedian_test_accuracies = [np.median(metrics[m][\"test_acc\"]) for m in labels]\n\nplt.figure(figsize=(8, 5))\nbars = plt.bar(labels, median_test_accuracies, color=[\"cornflowerblue\", \"lightcoral\", \"lightgreen\"])\nplt.ylabel(\"Median Test Accuracy\")\nplt.title(\"APH Dataset: GOSDT vs GBDT (SMOTE + Stratified KFold)\")\nfor bar in bars:\n    yval = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2.0, yval, f'{yval:.3f}', va='bottom', ha='center')\nplt.xticks(rotation=15)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install gosdt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# GOSDT+ TH","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport time\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom gosdt import GOSDTClassifier, ThresholdGuessBinarizer, NumericBinarizer\n\n# === Parameters ===\nGBDT_N_EST = 40\nGBDT_MAX_DEPTH = 1\nREGULARIZATION = 0.001\nDEPTH_BUDGET = 3\nTIME_LIMIT = 1800\nSEED = 42\n\n# === Load dataset ===\ntry:\n    df = pd.read_csv(\"/kaggle/input/final-compas-15062025/compas (4).csv\")\nexcept FileNotFoundError:\n    print(\"Error: compas (4).csv not found.\")\n    exit()\n\nX, y = df.iloc[:, :-1], df.iloc[:, -1]\n\n# === Initialize metrics ===\nmetrics = {\n    \"GOSDT_Guessed\": {\"train_time\": [], \"test_time\": [], \"train_acc\": [], \"test_acc\": []},\n    \"GOSDT_Guessed_Threshold_Time\": [],\n    \"GOSDT_Numerical\": {\"train_time\": [], \"test_time\": [], \"train_acc\": [], \"test_acc\": []},\n}\n\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n\nfor fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n    print(f\"\\n=== Fold {fold + 1} ===\")\n\n    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n\n    ##### GOSDT with ThresholdGuessBinarizer #####\n    print(\"-> Training GOSDT (Guessed Thresholds)\")\n\n    tgb = ThresholdGuessBinarizer(n_estimators=GBDT_N_EST, max_depth=GBDT_MAX_DEPTH, random_state=SEED)\n    tgb.set_output(transform=\"pandas\")\n\n    start_thresh = time.time()\n    X_train_guessed = tgb.fit_transform(X_train.copy(), y_train.copy())\n    thresh_time = time.time() - start_thresh\n\n    X_test_guessed = tgb.transform(X_test.copy())\n\n    clf_guessed = GOSDTClassifier(\n        regularization=REGULARIZATION,\n        depth_budget=DEPTH_BUDGET,\n        time_limit=TIME_LIMIT,\n        verbose=False,\n    )\n\n    start_train = time.time()\n    clf_guessed.fit(X_train_guessed, y_train)\n    gosdt_train_time = time.time() - start_train\n\n    start_test = time.time()\n    y_pred_train = clf_guessed.predict(X_train_guessed)\n    y_pred_test = clf_guessed.predict(X_test_guessed)\n    test_time = time.time() - start_test\n\n    metrics[\"GOSDT_Guessed_Threshold_Time\"].append(thresh_time)\n    metrics[\"GOSDT_Guessed\"][\"train_time\"].append(gosdt_train_time)\n    metrics[\"GOSDT_Guessed\"][\"test_time\"].append(test_time)\n    metrics[\"GOSDT_Guessed\"][\"train_acc\"].append(accuracy_score(y_train, y_pred_train))\n    metrics[\"GOSDT_Guessed\"][\"test_acc\"].append(accuracy_score(y_test, y_pred_test))\n    print(f\"   Train Acc: {accuracy_score(y_train, y_pred_train):.4f}, Test Acc: {accuracy_score(y_test, y_pred_test):.4f}, GOSDT Time: {gosdt_train_time:.2f}s, Threshold Time: {thresh_time:.2f}s\")\n\n    ##### GOSDT with NumericBinarizer #####\n    print(\"-> Training GOSDT (Numeric Binarizer)\")\n\n    nb = NumericBinarizer()\n    nb.set_output(transform=\"pandas\")\n    X_train_num = nb.fit_transform(X_train.copy(), y_train.copy())\n    X_test_num = nb.transform(X_test.copy())\n\n    clf_num = GOSDTClassifier(\n        regularization=REGULARIZATION,\n        depth_budget=DEPTH_BUDGET,\n        time_limit=TIME_LIMIT,\n        verbose=False,\n    )\n\n    start_train = time.time()\n    clf_num.fit(X_train_num, y_train)\n    gosdt_num_time = time.time() - start_train\n\n    start_test = time.time()\n    y_pred_train_num = clf_num.predict(X_train_num)\n    y_pred_test_num = clf_num.predict(X_test_num)\n    test_time_num = time.time() - start_test\n\n    metrics[\"GOSDT_Numerical\"][\"train_time\"].append(gosdt_num_time)\n    metrics[\"GOSDT_Numerical\"][\"test_time\"].append(test_time_num)\n    metrics[\"GOSDT_Numerical\"][\"train_acc\"].append(accuracy_score(y_train, y_pred_train_num))\n    metrics[\"GOSDT_Numerical\"][\"test_acc\"].append(accuracy_score(y_test, y_pred_test_num))\n    print(f\"   Train Acc: {accuracy_score(y_train, y_pred_train_num):.4f}, Test Acc: {accuracy_score(y_test, y_pred_test_num):.4f}, GOSDT Time: {gosdt_num_time:.2f}s\")\n\n# === Display Median Results ===\nprint(\"\\n=== Median Results Over 5 Folds ===\")\nfor model_name, data in metrics.items():\n    if isinstance(data, dict):\n        print(f\"\\n{model_name}:\")\n        print(f\"  Train Accuracy: {np.median(data['train_acc']):.4f}\")\n        print(f\"  Test Accuracy:  {np.median(data['test_acc']):.4f}\")\n        print(f\"  GOSDT Train Time: {np.median(data['train_time']):.4f}s\")\n        print(f\"  Prediction Time: {np.median(data['test_time']):.4f}s\")\n\nprint(f\"\\nThreshold Guessing Time (median): {np.median(metrics['GOSDT_Guessed_Threshold_Time']):.4f}s\")\n\n# === Plotting Training Time Breakdown ===\nplt.figure(figsize=(10, 6))\n\nlabels = [\"GOSDT w/ Guessing\", \"GOSDT w/o Guessing\"]\nx = np.arange(len(labels))\n\nguess_time = np.median(metrics[\"GOSDT_Guessed\"][\"train_time\"])\nthresh_time = np.median(metrics[\"GOSDT_Guessed_Threshold_Time\"])\nnumeric_time = np.median(metrics[\"GOSDT_Numerical\"][\"train_time\"])\n\n# Stacked bar for guessed threshold + GOSDT\nplt.bar(x[0], thresh_time, color='green', label='Threshold Guessing Time')\nplt.bar(x[0], guess_time, bottom=thresh_time, color='cornflowerblue', label='GOSDT Train Time (Guessed)')\n\n# Plain bar for numeric GOSDT\nplt.bar(x[1], numeric_time, color='orange', label='GOSDT Train Time (Numeric)')\n\nplt.ylabel(\"Median Training Time (log scale, seconds)\")\nplt.title(\"Training Time Breakdown\")\nplt.xticks(x, labels)\nplt.yscale(\"log\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# GOSDT+th APH","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport time\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom imblearn.over_sampling import SMOTE\nfrom gosdt import GOSDTClassifier, ThresholdGuessBinarizer, NumericBinarizer\n\n# Load Antepartum Hemorrhage data\n# df = pd.read_csv(\"/content/aph.csv\")  # Uncomment and update the path if needed\n# X, y = df.iloc[:, :-1], df.iloc[:, -1]\nGBDT_N_EST = 200\nGBDT_MAX_DEPTH = 1\nSEED = 42\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n\nmetrics = {\n    \"GOSDT_Guessed\": {\"train_acc\": [], \"test_acc\": []},\n    \"GOSDT_Numerical\": {\"train_acc\": [], \"test_acc\": []},\n    \"GBDT_Baseline\": {\"train_acc\": [], \"test_acc\": []},\n}\n\ntimes = {\n    \"GOSDT_Guessed\": {\"train_time\": [], \"test_time\": []},\n    \"GOSDT_Numerical\": {\"train_time\": [], \"test_time\": []},\n    \"GBDT_Baseline\": {\"train_time\": [], \"test_time\": []},\n}\n\nfor fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n    print(f\"\\n=== Fold {fold + 1} ===\")\n\n    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n\n    # SMOTE on training data only\n    smote = SMOTE(random_state=SEED, sampling_strategy=0.8)\n    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n\n    # -------- GOSDT with ThresholdGuessBinarizer --------\n    print(\"-> GOSDT (ThresholdGuessBinarizer)\")\n    tgb = ThresholdGuessBinarizer(n_estimators=GBDT_N_EST, max_depth=GBDT_MAX_DEPTH, random_state=SEED)\n    tgb.set_output(transform=\"pandas\")\n    X_train_guess = tgb.fit_transform(X_train_res.copy(), y_train_res.copy())\n    X_test_guess = tgb.transform(X_test.copy())\n\n    clf_guess = GOSDTClassifier(regularization=0.001, depth_budget=2, time_limit=1800)\n\n    start_train = time.time()\n    clf_guess.fit(X_train_guess, y_train_res)  # No y_ref parameter here\n    end_train = time.time()\n    times[\"GOSDT_Guessed\"][\"train_time\"].append(end_train - start_train)\n\n    start_test = time.time()\n    y_pred_test_g = clf_guess.predict(X_test_guess)\n    end_test = time.time()\n    times[\"GOSDT_Guessed\"][\"test_time\"].append(end_test - start_test)\n\n    y_pred_train_g = clf_guess.predict(X_train_guess)\n\n    metrics[\"GOSDT_Guessed\"][\"train_acc\"].append(accuracy_score(y_train_res, y_pred_train_g))\n    metrics[\"GOSDT_Guessed\"][\"test_acc\"].append(accuracy_score(y_test, y_pred_test_g))\n\n    # -------- GOSDT with NumericBinarizer --------\n    print(\"-> GOSDT (NumericBinarizer)\")\n    nb = NumericBinarizer()\n    nb.set_output(transform=\"pandas\")\n    X_train_num = nb.fit_transform(X_train_res.copy(), y_train_res.copy())\n    X_test_num = nb.transform(X_test.copy())\n\n    clf_num = GOSDTClassifier(regularization=0.001, depth_budget=1, time_limit=1800)\n\n    start_train = time.time()\n    clf_num.fit(X_train_num, y_train_res)\n    end_train = time.time()\n    times[\"GOSDT_Numerical\"][\"train_time\"].append(end_train - start_train)\n\n    start_test = time.time()\n    y_pred_test_n = clf_num.predict(X_test_num)\n    end_test = time.time()\n    times[\"GOSDT_Numerical\"][\"test_time\"].append(end_test - start_test)\n\n    y_pred_train_n = clf_num.predict(X_train_num)\n\n    metrics[\"GOSDT_Numerical\"][\"train_acc\"].append(accuracy_score(y_train_res, y_pred_train_n))\n    metrics[\"GOSDT_Numerical\"][\"test_acc\"].append(accuracy_score(y_test, y_pred_test_n))\n\n    # -------- GBDT Baseline --------\n    print(\"-> GBDT Baseline\")\n    gbdt = GradientBoostingClassifier(n_estimators=GBDT_N_EST, max_depth=GBDT_MAX_DEPTH, random_state=SEED)\n\n    start_train = time.time()\n    gbdt.fit(X_train_res, y_train_res)\n    end_train = time.time()\n    times[\"GBDT_Baseline\"][\"train_time\"].append(end_train - start_train)\n\n    start_test = time.time()\n    y_pred_test_b = gbdt.predict(X_test)\n    end_test = time.time()\n    times[\"GBDT_Baseline\"][\"test_time\"].append(end_test - start_test)\n\n    y_pred_train_b = gbdt.predict(X_train_res)\n\n    metrics[\"GBDT_Baseline\"][\"train_acc\"].append(accuracy_score(y_train_res, y_pred_train_b))\n    metrics[\"GBDT_Baseline\"][\"test_acc\"].append(accuracy_score(y_test, y_pred_test_b))\n\n# ------------------ Accuracy Results ------------------\nprint(\"\\n=== Median Accuracy Results Over Folds ===\")\nfor model in metrics:\n    print(f\"\\n{model}:\")\n    print(f\"  Median Train Accuracy: {np.median(metrics[model]['train_acc']):.4f}\")\n    print(f\"  Median Test Accuracy:  {np.median(metrics[model]['test_acc']):.4f}\")\n\n# ------------------ Timing Results ------------------\nprint(\"\\n=== Median Training & Testing Time (seconds) ===\")\nfor model in times:\n    print(f\"\\n{model}:\")\n    print(f\"  Median Train Time: {np.median(times[model]['train_time']):.2f} sec\")\n    print(f\"  Median Test Time:  {np.median(times[model]['test_time']):.4f} sec\")\n\n# ------------------ Optional: Plot Accuracy ------------------\nlabels = list(metrics.keys())\nmedian_test_accuracies = [np.median(metrics[m][\"test_acc\"]) for m in labels]\n\nplt.figure(figsize=(8, 5))\nbars = plt.bar(labels, median_test_accuracies, color=[\"cornflowerblue\", \"lightcoral\", \"lightgreen\"])\nplt.ylabel(\"Median Test Accuracy\")\nplt.title(\"APH Dataset: GOSDT vs GBDT (SMOTE + Stratified KFold)\")\nfor bar in bars:\n    yval = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2.0, yval, f'{yval:.3f}', va='bottom', ha='center')\nplt.xticks(rotation=15)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install gosdt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport time\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom imblearn.over_sampling import SMOTE\nfrom gosdt import GOSDTClassifier, ThresholdGuessBinarizer, NumericBinarizer\n\n# Load Antepartum Hemorrhage data\n# df = pd.read_csv(\"/content/aph.csv\")  # Uncomment and update the path if needed\n# X, y = df.iloc[:, :-1], df.iloc[:, -1]\nGBDT_N_EST = 200\nGBDT_MAX_DEPTH = 1\nSEED = 42\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n\nmetrics = {\n    \"GOSDT_Guessed\": {\"train_acc\": [], \"test_acc\": []},\n    \"GOSDT_Numerical\": {\"train_acc\": [], \"test_acc\": []},\n}\n\ntimes = {\n    \"GOSDT_Guessed\": {\"train_time\": [], \"test_time\": [], \"threshold_guess_time\": []},\n    \"GOSDT_Numerical\": {\"train_time\": [], \"test_time\": []},\n}\n\nfor fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n    print(f\"\\n=== Fold {fold + 1} ===\")\n\n    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n\n    # SMOTE on training data only\n    smote = SMOTE(random_state=SEED, sampling_strategy=0.8)\n    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n\n    # -------- GOSDT with ThresholdGuessBinarizer --------\n    print(\"-> GOSDT (ThresholdGuessBinarizer)\")\n    tgb = ThresholdGuessBinarizer(n_estimators=GBDT_N_EST, max_depth=GBDT_MAX_DEPTH, random_state=SEED)\n    tgb.set_output(transform=\"pandas\")\n\n    start_guess = time.time()\n    X_train_guess = tgb.fit_transform(X_train_res.copy(), y_train_res.copy())\n    end_guess = time.time()\n    times[\"GOSDT_Guessed\"][\"threshold_guess_time\"].append(end_guess - start_guess)\n\n    X_test_guess = tgb.transform(X_test.copy())\n\n    clf_guess = GOSDTClassifier(regularization=0.001, depth_budget=2, time_limit=1800)\n\n    start_train = time.time()\n    clf_guess.fit(X_train_guess, y_train_res)\n    end_train = time.time()\n    times[\"GOSDT_Guessed\"][\"train_time\"].append(end_train - start_train)\n\n    start_test = time.time()\n    y_pred_test_g = clf_guess.predict(X_test_guess)\n    end_test = time.time()\n    times[\"GOSDT_Guessed\"][\"test_time\"].append(end_test - start_test)\n\n    y_pred_train_g = clf_guess.predict(X_train_guess)\n\n    metrics[\"GOSDT_Guessed\"][\"train_acc\"].append(accuracy_score(y_train_res, y_pred_train_g))\n    metrics[\"GOSDT_Guessed\"][\"test_acc\"].append(accuracy_score(y_test, y_pred_test_g))\n\n    # -------- GOSDT with NumericBinarizer --------\n    print(\"-> GOSDT (NumericBinarizer)\")\n    nb = NumericBinarizer()\n    nb.set_output(transform=\"pandas\")\n    X_train_num = nb.fit_transform(X_train_res.copy(), y_train_res.copy())\n    X_test_num = nb.transform(X_test.copy())\n\n    clf_num = GOSDTClassifier(regularization=0.001, depth_budget=1, time_limit=1800)\n\n    start_train = time.time()\n    clf_num.fit(X_train_num, y_train_res)\n    end_train = time.time()\n    times[\"GOSDT_Numerical\"][\"train_time\"].append(end_train - start_train)\n\n    start_test = time.time()\n    y_pred_test_n = clf_num.predict(X_test_num)\n    end_test = time.time()\n    times[\"GOSDT_Numerical\"][\"test_time\"].append(end_test - start_test)\n\n    y_pred_train_n = clf_num.predict(X_train_num)\n\n    metrics[\"GOSDT_Numerical\"][\"train_acc\"].append(accuracy_score(y_train_res, y_pred_train_n))\n    metrics[\"GOSDT_Numerical\"][\"test_acc\"].append(accuracy_score(y_test, y_pred_test_n))\n\n# ------------------ Accuracy Results ------------------\nprint(\"\\n=== Median Accuracy Results Over Folds ===\")\nfor model in metrics:\n    print(f\"\\n{model}:\")\n    print(f\"  Median Train Accuracy: {np.median(metrics[model]['train_acc']):.4f}\")\n    print(f\"  Median Test Accuracy:  {np.median(metrics[model]['test_acc']):.4f}\")\n\n# ------------------ Timing Results ------------------\nprint(\"\\n=== Median Training & Testing Time (seconds) ===\")\nfor model in times:\n    print(f\"\\n{model}:\")\n    if \"threshold_guess_time\" in times[model]:\n        print(f\"  Median Threshold Guessing Time: {np.median(times[model]['threshold_guess_time']):.4f} sec\")\n    print(f\"  Median Train Time: {np.median(times[model]['train_time']):.2f} sec\")\n    print(f\"  Median Test Time:  {np.median(times[model]['test_time']):.4f} sec\")\n\n# ------------------ Optional: Plot Accuracy ------------------\nlabels = list(metrics.keys())\nmedian_test_accuracies = [np.median(metrics[m][\"test_acc\"]) for m in labels]\n\nplt.figure(figsize=(8, 5))\nbars = plt.bar(labels, median_test_accuracies, color=[\"cornflowerblue\", \"lightcoral\"])\nplt.ylabel(\"Median Test Accuracy\")\nplt.title(\"APH Dataset: GOSDT Models (SMOTE + Stratified KFold)\")\nfor bar in bars:\n    yval = bar.get_height()\n    plt.text(bar.get_x() + bar.get_width()/2.0, yval, f'{yval:.3f}', va='bottom', ha='center')\nplt.xticks(rotation=15)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Data for D=3 (COMPAS DATASET)\n# Note: 'GOSDT + Guessing Strategy' is referred to as 'Ours' in the image\n# 'GOSDT' is referred to as 'gosdt+th+lb'\n# 'GBDT' is referred to as 'dl8.5' or 'GBDT' depending on context in the image legend,\n# but for D=3 table, it's just 'GBDT'. We'll align with the legend.\n\ndata = {\n    'GOSDT': {\n        'training_time': 13.5897,\n        'train_accuracy': 0.6857,\n        'test_accuracy': 0.6748\n    },\n    'GOSDT + Guessing Strategy': {\n        'training_time': 5.1949,\n        'train_accuracy': 0.6857,\n        'test_accuracy': 0.6748\n    },\n    \n}\n\n# Baseline accuracies from the image for D=3\n# These are approximate values taken visually from the horizontal dashed lines.\nbaseline_train_accuracy = 0.6949\nbaseline_test_accuracy = 0.6819\n\n# Setup plot styles\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.sans-serif'] = ['Inter'] # Assuming 'Inter' font is installed or a suitable sans-serif\nplt.rcParams['font.size'] = 12\nplt.rcParams['axes.labelsize'] = 14\nplt.rcParams['xtick.labelsize'] = 12\nplt.rcParams['ytick.labelsize'] = 12\nplt.rcParams['legend.fontsize'] = 12\nplt.rcParams['figure.titlesize'] = 16\n\n# Define colors and markers for each method to match the image legend\ncolors = {\n    'GOSDT': '#4CAF50',  # Greenish for gosdt+th+lb (approximating blue-green in image)\n    'GOSDT + Guessing Strategy': '#FFC107', # Orange for Ours (star)\n    'GBDT': '#8884d8' # Purple-ish for GBDT/dl8.5\n}\n\nmarkers = {\n    'GOSDT': 's',  # Square for GOSDT\n    'GOSDT + Guessing Strategy': '*', # Star for Ours\n    'GBDT': 'o'  # Circle for GBDT/dl8.5\n}\n\n# Figure and Subplots\nfig, axes = plt.subplots(1, 2, figsize=(16, 7)) # 1 row, 2 columns for side-by-side plots\nfig.suptitle('Accuracy vs Run Time (COMPAS, depth limit=3)', fontsize=18, y=1.02)\n\n\n# --- Plot 1: Training Accuracy vs Run Time ---\nax1 = axes[0]\nax1.set_title('Training Accuracy vs Run Time', fontsize=16)\nax1.set_xlabel('Training Time (s) (log scale)', fontsize=14)\nax1.set_ylabel('Training Accuracy', fontsize=14)\nax1.set_xscale('log') # Set x-axis to logarithmic scale\nax1.set_xlim(0.1, 100) # Set x-axis limits\nax1.set_ylim(0.65, 0.71) # Set y-axis limits for training accuracy\nax1.grid(True, which=\"both\", ls=\"--\", c='0.7') # Add grid lines\n\n# Plot data points for Training Accuracy\nfor method, vals in data.items():\n    ax1.scatter(\n        vals['training_time'],\n        vals['train_accuracy'],\n        s=200, # Size of the markers\n        color=colors[method],\n        marker=markers[method],\n        label=method,\n        edgecolor='black', # Add edge for better visibility\n        linewidth=0.8\n    )\n\n# Add baseline line for Training Accuracy\nax1.axhline(\n    y=baseline_train_accuracy,\n    color='black',\n    linestyle='--',\n    linewidth=1.5,\n    label=f'Baseline ({baseline_train_accuracy})'\n)\n\n# Add text annotations for 'run time saving' and 'timeout' if applicable and visually suggested by the image.\n# This requires knowing the specific points for these annotations, which aren't in the table.\n# For now, we'll just plot the data points and the baseline.\n# If you provide specific coordinates for these arrows/labels, they can be added.\n\nax1.legend(loc='lower left', bbox_to_anchor=(0, 0)) # Adjust legend position\n\n\n# --- Plot 2: Test Accuracy vs Run Time ---\nax2 = axes[1]\nax2.set_title('Test Accuracy vs Run Time', fontsize=16)\nax2.set_xlabel('Training Time (s) (log scale)', fontsize=14)\nax2.set_ylabel('Test Accuracy', fontsize=14)\nax2.set_xscale('log') # Set x-axis to logarithmic scale\nax2.set_xlim(0.1, 100) # Set x-axis limits\nax2.set_ylim(0.65, 0.71) # Set y-axis limits for test accuracy\nax2.grid(True, which=\"both\", ls=\"--\", c='0.7') # Add grid lines\n\n# Plot data points for Test Accuracy\nfor method, vals in data.items():\n    ax2.scatter(\n        vals['training_time'],\n        vals['test_accuracy'],\n        s=200, # Size of the markers\n        color=colors[method],\n        marker=markers[method],\n        label=method,\n        edgecolor='black',\n        linewidth=0.8\n    )\n\n# Add baseline line for Test Accuracy\nax2.axhline(\n    y=baseline_test_accuracy,\n    color='black',\n    linestyle='--',\n    linewidth=1.5,\n    label=f'Baseline ({baseline_test_accuracy})'\n)\n\n# Add text annotations if applicable (same as for training accuracy)\n\nax2.legend(loc='lower left', bbox_to_anchor=(0, 0)) # Adjust legend position\n\n\n# Adjust layout to prevent overlapping titles/labels\nplt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust rect to make space for the suptitle\n\n# Show the plot\nplt.show()\n\n# You can save the plot to a file if needed:\n# plt.savefig('accuracy_vs_runtime_d3.png', dpi=300, bbox_inches='tight')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install gosdt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport time\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom gosdt import GOSDTClassifier, ThresholdGuessBinarizer, NumericBinarizer\n\n# === Parameters ===\nGBDT_N_EST = 100\nGBDT_MAX_DEPTH = 3\nREGULARIZATION = 0.001\nDEPTH_BUDGET = 5\nTIME_LIMIT = 1800  # Increased for potentially longer NumericBinarizer runs\nSEED = 42\n\n# === Load dataset ===\n# Make sure to replace \"/content/compas (4).csv\" with the actual path to your CSV file\n# For example, if you upload it directly to Colab:\n# df = pd.read_csv(\"compas (4).csv\")\ntry:\n    df = pd.read_csv(\"/kaggle/input/final-compas-15062025/compas (4).csv\")\nexcept FileNotFoundError:\n    print(\"Error: compas (4).csv not found. Please upload the file or update the path.\")\n    exit()\n\nX, y = df.iloc[:, :-1], df.iloc[:, -1]\n\n# === Initialize metrics storage ===\nmetrics = {\n    \"GOSDT_Guessed\": {\"train_time\": [], \"test_time\": [], \"train_acc\": [], \"test_acc\": []},\n    \"GOSDT_Numerical\": {\"train_time\": [], \"test_time\": [], \"train_acc\": [], \"test_acc\": []},\n    \"GBDT_Baseline\": {\"train_time\": [], \"test_time\": [], \"train_acc\": [], \"test_acc\": []},\n}\n\n# === 5-Fold CV ===\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n\nfor fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n    print(f\"\\n=== Fold {fold + 1} ===\")\n\n    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n\n    ##### GOSDT with ThresholdGuessBinarizer + y_ref #####\n    print(\"-> Training GOSDT (Guessed Thresholds + y_ref)\")\n    tgb = ThresholdGuessBinarizer(n_estimators=GBDT_N_EST, max_depth=GBDT_MAX_DEPTH, random_state=SEED)\n    tgb.set_output(transform=\"pandas\")\n    X_train_guessed = tgb.fit_transform(X_train.copy(), y_train.copy()) # Use .copy() to avoid SettingWithCopyWarning\n    X_test_guessed = tgb.transform(X_test.copy())\n\n    # Create y_ref using the GBDT model trained on the original (non-binarized) training data for ThresholdGuessBinarizer's features\n    # The paper's approach implies the reference model's accuracy on subsets of data is used for lower bounds.\n    # For ThresholdGuessBinarizer itself, it learns thresholds from a GBDT trained on X_train.\n    # For y_ref for GOSDT, it should be predictions on the *binarized* training data from a reference model.\n    # The paper's Figure 1 caption: \"The black line shows the accuracy of a GBDT model\" (implying GBDT on original features).\n    # Section 4.3 \"Guessing Tighter Lower Bounds\": \"Let T be such a reference model and y_hat_i be the predictions... on training observation i\"\n    # \"Our guesses are guaranteed to predict as well or better than the black box tree-ensemble reference model:\n    #  taking the sparsest decision tree that makes the same predictions as the black box, our method will find this tree...\" (Section 1)\n    # This implies y_ref can come from a GBDT trained on the *same binarized features* GOSDT will use.\n\n    gbdt_ref_for_y_ref = GradientBoostingClassifier(n_estimators=GBDT_N_EST, max_depth=GBDT_MAX_DEPTH, random_state=SEED)\n    # Fit the reference GBDT on the same *guessed binarized* training data that GOSDT (guessed) will see\n    gbdt_ref_for_y_ref.fit(X_train_guessed, y_train)\n    y_ref = gbdt_ref_for_y_ref.predict(X_train_guessed)\n\n\n    clf_guessed = GOSDTClassifier(\n        regularization=REGULARIZATION,\n        depth_budget=DEPTH_BUDGET,\n        time_limit=TIME_LIMIT,\n        verbose=False, # Set to True for more GOSDT output\n        #random_seed=SEED # for reproducibility if GOSDT uses internal randomness\n    )\n\n    start_train = time.time()\n    clf_guessed.fit(X_train_guessed, y_train, y_ref=y_ref)\n    train_duration = time.time() - start_train\n\n    start_test = time.time()\n    y_pred_guessed_train = clf_guessed.predict(X_train_guessed) # For train accuracy\n    y_pred_guessed_test = clf_guessed.predict(X_test_guessed)   # For test accuracy\n    test_duration = time.time() - start_test # This is more prediction time than test fitting time\n\n    metrics[\"GOSDT_Guessed\"][\"train_time\"].append(train_duration)\n    metrics[\"GOSDT_Guessed\"][\"test_time\"].append(test_duration) # Storing prediction time here\n    metrics[\"GOSDT_Guessed\"][\"train_acc\"].append(accuracy_score(y_train, y_pred_guessed_train))\n    metrics[\"GOSDT_Guessed\"][\"test_acc\"].append(accuracy_score(y_test, y_pred_guessed_test))\n    print(f\"   GOSDT Guessed Train Acc: {accuracy_score(y_train, y_pred_guessed_train):.4f}, Test Acc: {accuracy_score(y_test, y_pred_guessed_test):.4f}, Train Time: {train_duration:.2f}s\")\n\n\n    ##### GOSDT with NumericalBinarizer #####\n    print(\"-> Training GOSDT (NumericalBinarizer)\")\n\n    nb = NumericBinarizer()\n    nb.set_output(transform=\"pandas\")\n    X_train_num = nb.fit_transform(X_train.copy(), y_train.copy())\n    X_test_num = nb.transform(X_test.copy())\n\n    clf_num = GOSDTClassifier(\n        regularization=REGULARIZATION,\n        depth_budget=DEPTH_BUDGET,\n        time_limit=TIME_LIMIT,\n        verbose=False,\n       # random_seed=SEED\n    )\n\n    start_train = time.time()\n    clf_num.fit(X_train_num, y_train)  # No y_ref for this baseline\n    train_duration_num = time.time() - start_train\n\n    start_test = time.time()\n    y_pred_num_train = clf_num.predict(X_train_num)\n    y_pred_num_test = clf_num.predict(X_test_num)\n    test_duration_num = time.time() - start_test\n\n    metrics[\"GOSDT_Numerical\"][\"train_time\"].append(train_duration_num)\n    metrics[\"GOSDT_Numerical\"][\"test_time\"].append(test_duration_num)\n    metrics[\"GOSDT_Numerical\"][\"train_acc\"].append(accuracy_score(y_train, y_pred_num_train))\n    metrics[\"GOSDT_Numerical\"][\"test_acc\"].append(accuracy_score(y_test, y_pred_num_test))\n    print(f\"   GOSDT Numerical Train Acc: {accuracy_score(y_train, y_pred_num_train):.4f}, Test Acc: {accuracy_score(y_test, y_pred_num_test):.4f}, Train Time: {train_duration_num:.2f}s\")\n\n\n    ##### GBDT Baseline #####\n    print(\"-> Training GBDT (Baseline on original features)\")\n\n    gbdt = GradientBoostingClassifier(n_estimators=GBDT_N_EST, max_depth=GBDT_MAX_DEPTH, random_state=SEED)\n\n    start_train = time.time()\n    gbdt.fit(X_train, y_train) # GBDT fits on original X_train\n    train_duration_gbdt = time.time() - start_train\n\n    start_test = time.time()\n    y_pred_gbdt_train = gbdt.predict(X_train)\n    y_pred_gbdt_test = gbdt.predict(X_test)\n    test_duration_gbdt = time.time() - start_test\n\n    metrics[\"GBDT_Baseline\"][\"train_time\"].append(train_duration_gbdt)\n    metrics[\"GBDT_Baseline\"][\"test_time\"].append(test_duration_gbdt)\n    metrics[\"GBDT_Baseline\"][\"train_acc\"].append(accuracy_score(y_train, y_pred_gbdt_train))\n    metrics[\"GBDT_Baseline\"][\"test_acc\"].append(accuracy_score(y_test, y_pred_gbdt_test))\n    print(f\"   GBDT Baseline Train Acc: {accuracy_score(y_train, y_pred_gbdt_train):.4f}, Test Acc: {accuracy_score(y_test, y_pred_gbdt_test):.4f}, Train Time: {train_duration_gbdt:.2f}s\")\n\n\n# === Display Results ===\nprint(\"\\n=== Median Results Over 5 Folds ===\") # Changed from Average to Median\nfor model_name, data in metrics.items():\n    print(f\"\\n{model_name}:\")\n    print(f\"  Train Accuracy: {np.median(data['train_acc']):.4f}\") # Changed to median\n    print(f\"  Test Accuracy:  {np.median(data['test_acc']):.4f}\")  # Changed to median\n    print(f\"  Train Time:     {np.median(data['train_time']):.4f}s\") # Changed to median\n    print(f\"  Prediction Time: {np.median(data['test_time']):.4f}s\") # Changed to median, clarified this is prediction time\n\n# === Plotting ===\nlabels = list(metrics.keys())\n# Ensure all metric lists are populated before taking median\nmedian_test_accuracies = [np.median(metrics[m][\"test_acc\"]) if metrics[m][\"test_acc\"] else np.nan for m in labels]\nmedian_train_times = [np.median(metrics[m][\"train_time\"]) if metrics[m][\"train_time\"] else np.nan for m in labels]\n\n# Plot: Accuracy\nplt.figure(figsize=(12, 5)) # Increased figure size for better readability\nplt.subplot(1, 2, 1)\nbars = plt.bar(labels, median_test_accuracies, color=['cornflowerblue', 'lightcoral', 'lightgreen'])\nplt.ylabel(\"Median Test Accuracy\")\nplt.title(\"Median Test Accuracy over 5 Folds\")\nplt.xticks(rotation=15, ha=\"right\") # Rotate labels for better fit\nfor bar in bars: # Add values on top of bars\n    yval = bar.get_height()\n    if not np.isnan(yval):\n        plt.text(bar.get_x() + bar.get_width()/2.0, yval, f'{yval:.3f}', va='bottom', ha='center') # GM\n\n\n# Plot: Training Time (log scale)\nplt.subplot(1, 2, 2)\nbars = plt.bar(labels, median_train_times, color=['cornflowerblue', 'lightcoral', 'lightgreen'])\nplt.yscale(\"log\")\nplt.ylabel(\"Median Train Time (s, log scale)\")\nplt.title(\"Median Training Time over 5 Folds\")\nplt.xticks(rotation=15, ha=\"right\")\nfor bar in bars: # Add values on top of bars\n    yval = bar.get_height()\n    if not np.isnan(yval):\n        plt.text(bar.get_x() + bar.get_width()/2.0, yval, f'{yval:.3f}', va='bottom', ha='center') # GM\n\nplt.tight_layout()\nplt.show()\n\n# Print GOSDT tree for one of the folds (e.g., last fold) if GOSDT was successful\nif 'clf_guessed' in locals() and clf_guessed.status_ == \"optimal\":\n    print(\"\\n--- Example GOSDT (Guessed) Tree (last fold) ---\")\n    print(clf_guessed.tree_)\nelif 'clf_guessed' in locals():\n    print(f\"\\n--- GOSDT (Guessed) Status (last fold): {clf_guessed.status_} ---\")\n\n\nif 'clf_num' in locals() and clf_num.status_ == \"optimal\":\n    print(\"\\n--- Example GOSDT (Numerical) Tree (last fold) ---\")\n    print(clf_num.tree_)\nelif 'clf_num' in locals():\n    print(f\"\\n--- GOSDT (Numerical) Status (last fold): {clf_num.status_} ---\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}